{
  "hotwords": {
    "probabilities" : {
      "en": "probabilities",
      "el": "πιθανότητες"
    },
    "arduino" : {
      "en": "arduino"
    },
    "embedded" : {
      "en": "embedded",
      "el": "ενσωματωμένα"
    },
    "zig" : {
      "en": "zig"
    },
    "graduation": {
      "en": "graduation",
      "el": "αποφοίτηση"
    },
    "masters": {
      "en": "masters",
      "el": "μεταπτυχιακό"
    },
    "vuejs": {
      "en": "vuejs"
    },
    "website": {
      "en": "website",
      "el": "ιστοσελίδα"
    },
    "update": {
      "en": "update",
      "el": "ενημέρωση"
    },
    "prototype": {
      "en": "prototype",
      "el": "πρωτότυπο"
    },
    "game": {
      "en": "game",
      "el": "παιχνίδι"
    },
    "thesis": {
      "en": "thesis",
      "el": "πτυχιακή"
    },
    "university": {
      "en": "university",
      "el": "πανεπιστήμιο"
    },
    "physics": {
      "en": "physics",
      "el": "φυσική"
    },
    "Dragonfly": {
      "en": "Dragonfly"
    },
    "Godot": {
      "en": "Godot"
    },
    "World of Goo": {
      "en": "World of Goo"
    },
    "translation": {
      "en": "translation",
      "el": "μετάφραση"
    },
    "greek": {
      "en": "greek",
      "el": "ελληνικά"
    },
    "mod": {
      "en": "mod",
      "el": "τροποποίηση"
    },
    "vulkan": {
      "en": "vulkan"
    },
    "graphics": {
      "en": "graphics",
      "el": "γραφικά"
    },
    "rendering": {
      "en": "rendering",
      "el": "οπτικοποίηση"
    },
    "overloading": {
      "en": "overloading",
      "el": "υπερφόρτωση"
    },
    "cpp": {
      "en": "cpp"
    },
    "operators": {
      "en": "operators",
      "el": "τελεστές"
    },
    "code": {
      "en": "code",
      "el": "κώδικας"
    },
    "math": {
      "en": "math",
      "el": "μαθηματικά"
    },
    "example": {
      "en": "example",
      "el": "παράδειγμα"
    },
    "random": {
      "en": "random",
      "el": "τυχαιότητες"
    }
  },
  "posts": [
    {
      "slug": "monty_hall",
      "hotwords": ["math", "random", "physics", "probabilities"],
      "featured_image": "https://animalia-life.club/data_images/goat/goat4.jpg",
      "title": {
        "en": "Birthdays, goats and electrons-oracles",
        "el": "Γενέθλια, κατσίκες και ηλεκτρόνια-Πυθίες"
      },
      "summary": {
        "en": "AKA \"Probabilities: Everyone's bane of existence\"",
        "el": "Εναλλακτικά «Πιθανότητες: Ο άσπονδος εχθρός της υφηλίου»"
      },
      "updated": "2025-04-02T00:00:00.000Z",
      "published": "2025-03-01T00:00:00.000Z",
      "author": "Mantis",
      "body": {
        "en": "<p>In the Networks Security course I am attending this semester, when talking about hashing algorithms, we stumbled upon the so-called \"Birthday Paradox\" of Probability theory. This pesky paradox claims that, unintuitively, the chance of meeting someone in a room with the same birthday as us grows <i>a lot</i> faster than we'd think at first. In fact, it grows so fast that it only takes <b>23 people</b> for that chance to be around 50%!!</p><p>The derivation of this result is actually much simpler than it seems; for a group of n people, it's simply a matter of finding all the possible combinations of birthdays into sets of n and all the possible combinations of <i>completely differing</i> birthdays (into sets of n), taking the ratio of that and finding the complementary probability (so, the percentage of all the combinations of birthdays into sets of n that have at least two same dates). Despite the wording, it's really just an introductory combinatorics exercise. The result, nevertheless, is still astounding!</p><p>This made me think generally of how bad of an intuition people have for probabilities and specifically how they relate to <i>knowledge</i> of an event; like, in this example, our brains subtly replace the \"probability of two people having the same birthday\" query with \"probability of a person having the same birthday as someone else the birthday of we know\". \"What?\", you will say, \"How does this make any difference?\". If you think about it, however, it is significantly different! Let's say your bday is in the 20th May and you wanted to find people whose birthday was at the same date. You'd find way less sets that have multiple \"20th of May\"s in them compared to multiple \"any date whatsoever\"s (there are a lot more days than the 20th of May, afterall!). Hence, it's generally much more difficult to find two people that share a <i>specific</i> birthday, compared to just finding two people who just happen to have the same birthday. This is also the idea behind many hashing algorithm attacks: whilst it's generally difficult to to find a plaintext that matches to a <i>specific</i> hash (the so-called 2nd preimage attack), finding two plaintexts with the same hash is not at all difficult, if the hash has a small enough length (thus you have a collision attack).</p><p>This bad intuition we have about knowledge ties to another paradox of probability theory: The Monty Hall Problem!</p><p>The Monty Hall problem asserts the following: <i>Assume you are the finalist on Monty Hall's \"Let's Make a Deal\" TV show and you are presented with three doors. Two have goats in them, one a glorious new car (guess which of the three you want to get). You get to pick a door. Once you make your choice, Monty will reveal a door with a goat to you and ask you if you want to switch or stay. Is it less or more risky to switch?</i></p><p>Believe it or not, this problem has stumped even the best of the best of mathematicians (further proof that television was a mistake). Most people assert that there's no difference in switching or not once the goat door is revealed. But this is WRONG! Switching actually <i>does</i> benefit you more than staying. Why though? Let's go through this, step by step:</p><p>Obviously, the moment you make your first choice, you will have an equal chance to pick either one of the goats or the car (unless you are not telling us something). Hence, 3 doors, 2 goats, 1 car makes ~67% chance to get a goat, ~33% to get a car. What happens when Monty opens the goat door though? \"Now I have to pick between my door and the other one,\" you'll probably think \"2 doors, 1 goat, 1 car, 50-50 chance for either, no point in switching\"</p><p>But do you <i>actually</i> pick between a goat door and a car door in the second round? You'd be surprised to hear that the answer is no and that you instead get to pick between your current door and <i>the other two doors</i>! And if you crunch the numbers up, there's a <i>67% chance<i> in getting a car if you open two doors!</p><p>This, probably world-theory-destroying, fact I revealed to you must have stumped you, most likely. \"The rules of the game specifically state that I get to pick only one door, not two doors, stupid\". True, I will respond. You do get to pick only one door each time, <i>in paper</i>. However, ponder for a moment on Monty's choice to reveal a goat door to you and remember what I said about people getting bamboozled when knowledge meets probability; Monty <b>already knows</b> what is behind each door. He knows where the car is and where the goats are. His choice to open a goat door is not random at all. It's quite precalculated. Hence, that choice is equivalent to him saying \"There's a 100% chance that there is a goat in one of the other two doors you didn't pick. Let me prove this to you [opens goat door]\". And you don't even really need to see the goat to know that: if your current door is a goat, the other one must be in one of the other doors. If your current door is a car, all the others are goats. You aren't told something you already do not know, and hence nothing is affected: The door is theoretically unopened!</p><p>In other words, Monty has just played you like a fool: he has subtly asked you to pick between opening one door of your choice or the other two doors and to further confuse you, he prematurely opened one of the other doors for you; always the one that has a goat, never a car. The fact that this is true, the fact that switching is essentially the same as opening two doors instead of one and thus raising the probability of getting a car to 67% is not just a theoretical finding either; plenty of simulations of this \"experiment\" (as probabilists would call it) or \"game\" (as game theorists would) have shown that switching is the better option.</p><p>This talk about probability and knowledge concludes with the final thing I would like to talk about and that I firmly believe \"science communicators\" have completely butchered: quantum entanglement. Quantum entanglement posits that two particles that are <i>exactly the same</i> and their probabilities to measure a specific value for a property of theirs essentially \"associated with each other\" (hence the name \"entanglement\") will keep that association no matter how far apart they are separated (at least until this system is measured in such a way that its state is ruined). This means that once we measure one particle, <i>we automatically know what we'll measure for the other particle</i> (this is what Einstein called \"spooky action at a distance\").</p><p>In probability terms, let's say that we have a system of two particles <i>that are exactly the same</i> with spins (spin being quantum physics black magic that relates to magnetism, no need to be concerned with its exact semantics for the following) that can be <b>up</b> or <b>down</b>. Let's also say that we know the whole system has no spin: This means that, in total, our particles must be one up, one down; remember that, because they are exactly the same, at this point, we cannot really pinpoint which has which. Hence, the probability of each particle being up or down is 50%.</p><p>Now let's say we spread them far apart; we somehow send one particle to an observation station A and the other to observation station B, lightyears apart from A (ignore the unrealisticness of this experiment, just go with the flow). Because of the entanglement, there must still be no spin in total. So, if observation station A measures its particle and finds its spin is up, the other one must be down: <i>It knows 100% that the spin of the other particle is down</i>. \"FTL TRANSMISSIONS REAL?\" some people might cry with glee when listening to that fact. But this is where the 'gotcha' comes in: <i>A</i> knows that. Not B. B being unaware of what A measured, <i>until</i> it receives intel about it, cannot make any assumptions on the current state of the system. Hence, <i>B will always measure a 50% chance for either spin up or down, should he be unaware of or ignore A's measurement</i>. In more mathy terms, it is <i>always true</i> that \\(P_B(\"up\") = P_B(\"down\") = 0.5\\).</p><figure><img src=\"https://raw.githubusercontent.com/xmamalou/blog-posts/refs/heads/master/assets/note.jpg\" alt=\"note\" width=\"500\"></p> <figcaption>Even though we can tell what B's observations will be based on A's, covering up A's observations will make B's seem completely random. That's what B would \"experience\" from their side.</figcaption></figure><p>As with the other paradoxes, the culprit here is knowledge: A can make assumptions about B's particle exactly because the former has knowledge of the state of their own particle. But because B has no knowledge of A's particle state, nothing from B's side is really affected. Hence, even though that \"spooky action at a distance\" is a real thing, causing a particle to assume a state based on its pair, even if it's <i>far far away</i> from it, this pheonomenon's more anticlimactic than it seems, because the observer of that particle still needs to be notified that it has happened in the first place!</p><p>Long story short, these three paradoxes are amongst my favourite when it comes to probabilities, because it showcases how bad we are at wrapping our head around probabilities; if \"knowledge\" comes into the mix, we are completely flabbergasted! So, from this point on, be diligent and remember how knowing can affect something random; it will save you a lot of headaches!</p>"
      }
    },
    {
      "slug": "ziguino",
      "hotwords": ["zig", "embedded", "arduino"],
      "featured_image": "https://raw.githubusercontent.com/xmamalou/blog-posts/refs/heads/master/assets/ziggy.webp",
      "title": {
        "en" : "Getting Ziggy with Arduino",
        "el" : "Παίζοντας με το Zig στο Arduino"
      },
      "summary": {
        "en" : "Shoving Zig wherever I can",
        "el" : "Χώνοντας την Zig όπου μπορώ"
      },
      "updated": "2025-03-01T00:00:00.000Z",
      "published": "2025-03-01T00:00:00.000Z",
      "author": "Mantis",
      "body" : {
        "en" : "<p>The last couple of weeks I remembered that my Arduino Uno board existed, so I decided to put it (and my newly found embedded knowledge) to use. And what better way to do this than spreading the Zig propaganda to it as well!</p><p>So, I sat down and started reading all I would need to make this work. My board is an Arduino Uno R3, which uses an Atmega328p processor, which itself uses the AVR ISA, a RISC-like ISA. Phew, at least I won't have to read much!</p><p>After studying up to the point that I needed, it was time to get my hands dirty! And what better program to create than the \"Hello World\" of Arduino programs? a blinking LED! First thing I did was to create the Zig equivalent of the <code>pinMode</code> function in the Arduino API.</p><p>In the R3 board, the (digital) pins' IO mode is controlled by two 8-bit registers in the CPU called <code>DDRD</code> and <code>DDRB</code>. For example, if I want to enable pin 2 for output, I need to set the second bit of the <code>DDRD</code> register to 1. In the AVR ISA, this is done with the <code>sbi</code> instruction. Hence, using inline assembly, now I have my first Zig function:</p><pre>  pub fn set_bit(register: u8, bit: u4) void {\n    asm volatile (\"sbi %[register], %[bit]\"\n      :\n      : [bit] \"i\" (bit),\n       [register] \"i\" (register),\n    );\n  }</pre><p>Pretty neat and simple, right? (Way better than my first implementation, which was strictly <code>comptime</code>. Thank you inline assembly parameters!). The opposite action, setting a pin as input, is simply done using the instruction <code>cbi</code> which <i>clears</i> a bit of a register (duh!). Thus, we are now able to create the Zig equivalent of <code>pinMode</code>!</p><pre>  pub fn pin_mode(pin: digital_pin, mode: pin_direction) void {\n    const function: *const fn (u8, u4) void =\n      if (mode == .input) &set_bit else &clear_bit;\n    const pin_num = @intFromEnum(pin);\n\n    function(\n      if (pin_num & 8 == 8)\n        @intFromEnum(DDR.B)\n      else\n        @intFromEnum(DDR.D),\n      pin_num & 7,\n    );\n  }</pre><p>For this one, I created two enums, one called <code>digital_pin</code>, which represents all the digital pins on the R3 and maps to an enum called <code>DDR</code> which simply itself maps its values to the numbers associated with these registers in the ISA. <code>pin_direction</code> is just a simple enum with two fields: <code>.input</code> and <code>.output</code>. This one just selects the appropriate function to call each time. The former enum, on the other hand, is used to find which register to change and what bits; if the pin is above 8 (including 8), that means we have to use the DDRB register, otherwise, the DDRD one will do.</p><p>Sending output to a pin is done with exactly the same thinking process as with enabling the pins. The difference is that now you have to edit the registers <code>PORTB, PORTD</code>. To finish the blinking LED program, I created a very shoddy soft timer, which pretty much executes a bunch of <code>nop</code>'s, essentially making the CPU idle for some of its 20MHz cycles:</p><pre>  pub fn soft_delay(ticks: u8) void {\n    for (1..ticks, 1..125) |_, _| {\n      asm volatile (\"nop\");\n    }\n  }</pre><p>...Yeah, it's very rough. Also, I am pretty sure the Zig optimizer obliterates many of the instructions anyways. But hey, I managed to get a result out of this! That is something, right?</p><p>Making the final program was nothing more than just using the <code>pin_mode</code> to enable the second digital pin of the board and then just making a loop; turn on... wait... turn off...</p><p>Up to this point, there was not something I have been completely unfamiliar with. Setting up the build file for compiling to AVR was not difficult either; Zig supports that architecture officially. But then, comes the linker: since this was a freestanding program, I <i>had</i> to set up how things are placed in memory on my own! It's over, I thought. Thankfully, linker scripts are not as difficult as I initially thought! In fact, my embedded software book I used for my previous semester had an example of a linker script which I just copied over and adapted it for my own purposes.</p><p>Okay, Zig now happily builds the program. But it's still a file on my computer and, as far as I know, Windows does not like running AVR ELF files. So, I now have to flash it on my Arduino board. A neat tool exists for this (and generally for flashing boards that use AVR CPUs), <code>avrdude</code>. I simply had to type the command:</p><pre>  avrdude -c arduino -P COM3 -p m328p -U flash:w:zig-program:e</pre><p>This tells <code>avrdude</code> that it has to flash an arduino board with an Atmega328p CPU, connected in COM3, with the program <code>zig-program</code>, which is an ELF file (that's what the <code>:e</code> suffix is for!) The result is <i>AMAZING</i> (not really, but let me cherish it, it took me more work to do than it should):</p><figure> <img src=\"https://raw.githubusercontent.com/xmamalou/blog-posts/refs/heads/master/assets/blinky.gif\" alt=\"blinky light\" width=\"500\"></p> <figcaption>Hello Ziguino!</figcaption></figure>",
        "el" : "<p>Τις τελευταίες εβδομάδες, θυμήθηκα ότι το Arduino μου έχει, πράγματι, φυσική υπόσταση, οπότε αποφάσισα να το χρησιμοποιήσω (όπως και τις νεοσύστατες γνώσεις περί ενσωματωμένου λογισμικού). Και δεν νομίζω να υπάρχει καλύτερος τρόπος από το να το κολλήσω με το μικρόβιο της Zig!</p><p>Έτσι, κάθισα να μελετήσω ώστε να το καταφέρω αυτό. Έχω ένα Arduino Uno R3, το οποίο διαθέτει έναν Atmega328p επεξεργαστή, που με την σειρά του υλοποιεί την αρχιτεκτονική AVR, μία RISC-οειδή αρχιτεκτονική. Τουλάχιστον δεν θα έχω να διαβάσω πολύ!</p><p>Έχοντας, λοιπόν, μελετήσει αρκούντως ώστε να καταφέρω να κάνω <i>κάτι</i>, ήρθε η ώρα για δουλειά! Και τι καλύτερο πρόγραμμα για αρχή από το \"Hello World\" των προγραμμάτων Arduino; ένα LEDάκι που αναβοσβήνει! Το πρώτο πράγμα που έπρεπε, λοιπόν, να κάνω είναι να φτιάξω την αντίστοιχη Zig συνάρτηση της <code>pinMode</code> του Arduino API.</p><p>Στο Uno R3, η ροή των (ψηφιακών) θυρών ελέγχεται από δύο οχτάμπιτους καταχωρητές του επεξεργαστή, τους <code>DDRD</code> και <code>DDRB</code>. Για παράδειγμα, αν θέλω να θέσω την θύρα 2 ως έξοδο, πρέπει να ανεβάσω το δεύτερο μπιτ του <code>DDRD</code>. Στην AVR, χρησιμοποιούμε την εντολή <code>sbi</code>. Ως εκ τούτου, χρήσει συμβολικής γλώσσας, έχουμε τώρα την πρώτη μας συνάρτηση:</p><pre>  pub fn set_bit(register: u8, bit: u4) void {\n    asm volatile (\"sbi %[register], %[bit]\"\n      :\n      : [bit] \"i\" (bit),\n       [register] \"i\" (register),\n    );\n  }</pre><p>Απλούστατο, ναι; (Μακράν καλύτερο της πρώτης υλοποίησης, η οποία ήταν μία συνάρτηση αυστηρά <code>comptime</code>. Σας ευχαριστώ, παράμετροι συμβολικής γλώσσας!). Tο αντίστροφο, το να θέσουμε ως είσοδο μία θύρα, γίνεται απλά με την εντολή <code>cbi</code> η οποία <i>κατεβάζει</i> ένα μπιτ του καταχωρητή (απρόσμενο!). Είμαστε, λοιπόν, έτοιμοι να φτιάξουμε την Zig-οειδή <code>pinMode</code>!</p><pre>  pub fn pin_mode(pin: digital_pin, mode: pin_direction) void {\n    const function: *const fn (u8, u4) void =\n      if (mode == .input) &set_bit else &clear_bit;\n    const pin_num = @intFromEnum(pin);\n\n    function(\n      if (pin_num & 8 == 8)\n        @intFromEnum(DDR.B)\n      else\n        @intFromEnum(DDR.D),\n      pin_num & 7,\n    );\n  }</pre><p>Για αυτήν, έφτιαξα δύο απαριθμητές, έναν ονόματι <code>digital_pin</code>, αντιπροσωπεύοντα όλες τις ψηφιακές θύρες του Arduino και αντιστοιχιζόμενο σε έναν άλλο απαριθμητή, τον <code>DDR</code>, ο οποίος απλά αντιστοιχίζει τις τιμές του στους αριθμούς που η αρχιτεκτονική AVR αναγνωρίζει ως τους εκάστοτε καταχωρητές. <code>pin_direction</code> είναι ένας απαριθμητής με δύο μόνο τιμές: <code>.input</code> και <code>.output</code>. Δεν κάνει τίποτε άλλο από το να ορίζει ποια συνάρτηση πρέπει να κληθεί κάθε φορά. Ο πρώτος, από την άλλη, ορίζει ποιος καταχωρητής πρέπει να ανεβάσει ποιο μπιτ του· αν η θύρα έχει αριθμό μεγαλύτερο ή ίσο του 8, πρέπει να χρησιμοποιήσουμε τον καταχωρητή DDRB, ειδάλλως, τον DDRD.</p><p>Η αποστολή εξόδου σε μία θύρα ακολουθεί την ίδια λογική με όλα τα προηγούμενα. Η διαφορά είναι ότι τώρα πρέπει να χρησιμοποιήσουμε τους καταχωρητές <code>PORTB, PORTD</code>. Για να τελειώσω το προγραμματάκι μου, έφτιαξα ένα προχειρότατο και ανακριβέστατο χρονόμετρο, που απλά εκτελεί ένα μάτσο <code>nop</code> εντολές· με άλλα λόγια, το χρονόμετρο αυτό κάνει τον επεξεργαστή να λουφάρει για πολλούς από τους 20MHz κύκλους του:</p><pre>  pub fn soft_delay(ticks: u8) void {\n    for (1..ticks, 1..125) |_, _| {\n      asm volatile (\"nop\");\n    }\n  }</pre><p>...Ναι, δεν είναι ό,τι καλύτερο. Επίσης, είμαι πολύ σίγουρος ότι ο μεταγλωττιστής εξαφανίζει αρκετές από αυτές τις εντολές. Δουλεύει παρά ταύτα! Κάτι κι αυτό, ναι;</p><p>Το τελικό πρόγραμμα δεν ήταν τίποτε περισσότερο από το να χρησιμοποιήσω την <code>pin_mode</code> για να ενεργοποιήσω την δεύτερη θύρα του Arduino ως έξοδο και μετά να φτιάξω έναν απλούστατο βρόχο· άναψε... περίμενε... σβήσε...</p><p>Ως τώρα, δεν υπήρχε κάτι «υπερβολικά» άγνωστο για εμένα. Ούτε το αρχείο κατασκευής του προγράμματος ήταν δύσκολο να φτιαχτεί! Η Zig επίσημα αυτήν την αρχιτεκτονική την υποστηρίζει. Και τώρα έρχεται ο linker: ως πρόγραμμα που δεν τρέχει πάνω σε λειτοργικό, επαφίετο σε <i>εμένα</i> να ορίσω που θα μπουν τα πάντα στην μνήμη. «Πάει, τελείωσε», σκέφτηκα. Ευτυχώς, τα σκριπτάκια σύνδεσης είναι πολύ ευκολότερα απ'όσο νόμιζα! Μάλιστα, το βιβλίο ενσωματωμένου λογισμικού που χρησιμοποίησα το προηγούμενο εξάμηνο είχε ένα παράδειγμα το οποίο απλά αντέγραψα και προσήρμοσα στις ανάγκες μου.</p><p>Εντάξει, η Zig τώρα φτιάχνει το τελικό πρόγραμμα δίχως πείσματα. Μα και πάλι παραμένει απλά ένα αρχείο στον υπολογιστή μου και, απ'όσο γνωρίζω, τα Windows δεν τους αρέσει να τρέχουν αρχεία ELF, πόσο μάλλον στην AVR αρχιτεκτονική. Οπότε τώρα πρέπει να το φορτώσω στο Arduino μου. Ένα πολύ ωραίο εργαλειάκι υπάρχει για αυτό (και όχι μόνο για αυτό, αλλά για ό,τι έχει πάνω του έναν επεξεργαστή με AVR), το <code>avrdude</code>. Απλά πληκτρολόγησα την εντολή:</p><pre>  avrdude -c arduino -P COM3 -p m328p -U flash:w:zig-program:e</pre><p>Αυτή λέει στο <code>avrdude</code> ότι πρέπει να φορτώσει σε ένα Arduino με τον επεξεργαστή Atmega328p, συνδεδεμένο στην σειριακή θύρα COM3, το πρόγραμμα <code>zig-program</code>, το οποίο είναι σε μορφή ELF (το επίθημα <code>:e</code> αυτό σημαίνει!) Το αποτέλεσμα είναι <i>ΚΑΤΑΠΛΗΚΤΙΚΟ</i> (λέμε τώρα. Αλλά μου πήρε περισσότερο χρόνο απ'όσο θα έπρεπε, οπότε περί ορέξεως):</p><figure> <img src=\"https://raw.githubusercontent.com/xmamalou/blog-posts/refs/heads/master/assets/blinky.gif\" alt=\"blinky light\" width=\"500\"></p> <figcaption>Hello Ziguino!</figcaption></figure>"
      }
    },
    {
      "slug": "masters_round2",
      "hotwords": ["university", "masters"],
      "title": {
        "en": "Masters, round 2",
        "el": "Μεταπτυχιακό, γύρος 2"
      },
      "summary": {
        "en": "Another semester of grind",
        "el": "Άλλο ένα εξάμηνο δουλειάς"	
      },
      "updated": "2025-02-10T00:00:00.000Z",	
      "published": "2025-02-10T00:00:00.000Z",
      "author": "Mantis",
      "body" : {
        "en": "<p>With the first round of exams of my masters having finished, the new semester is just around the corner. And let me tell you, this one is more exciting than ever! And also kinda scary! VHDL, computer architectures, parallel systems, sensors, security... I'm feeling as if I'll blow up, but at least I'll blow up with (computery) style 😎. I've also been doing a bit of teacher assistance work (grading assignments), which I will also do in this next semester. I've got my work cutout for me!</p><p>On another topic, all those months that have passed made me realise that I don't really hate <i>Physics</i> itself. Rather, I hate the \"ultra-theoretical, no-experiments, zero-fucks-given, we-don't-know-what-we're-talking-about-but-we'll-still-say-it\" kind of physics. Also, my old department, because it reeked of elitist and snobbish personnel and students alike. It's kinda funny; a course about cellular and mobile networks done by a professor who did not care much about physics in the first place (still a good teacher though) was more successful in re-sparking my interest in physics compared to 4 years of physics in undergrad trying to spark that interest.</p><p>Having said that, I also decided to do a masters thesis that will not \"shun\" my undergrad; rather, the two fields should complement each other. In other words, I am currently looking for a thesis subject that is as relevant to Computer Engineering as it is to Astrophysics (my orientation in undergrad) and specifically to Space Physics (which was also my favourite class from all those we had in my orientation in undergrad; awesome teacher, awesome material) itself. Thankfully, I know this combo is something my current department cares about (we even launched a satellite to space recently, true story!)</p><p>Anyways, that's all. Happy belated New Year!</p>",
        "el": "<p>Με την πρώτη εξεταστική νάναι παρελθόν, το νέο εξάμηνο έχει σχεδόν καταφθάσει. Ένα θα σας πω: έχω κατενθουσιαστεί! Αλλά και σκιαχτεί! VHDL, αρχιτεκτονικές υπολογιστών, παράλληλα συστήματα, αισθητήρες, ασφάλεια... Νιώθω πως θα εκραγώ, αλλά τουλάχιστον θα εκραγώ με (ηλεκτρονικό) στυλ 😎. Παράλληλα εκτελώ και χρέη βοηθού, διορθώνοντας εργασίες, «παράδοση» που θα συνεχιστεί και στο επόμενο εξάμηνο. Έχω πολλά στο ακαδημαϊκό μου πιάτο!</p><p>Σε ένα παράλληλο θέμα, όλος αυτός ο χρόνος που πέρασε με έκανε να συνειδητοποιήσω ότι δεν μισώ την <i>Φυσική</i> αυτήν καθ'αυτήν. Όχι· μισούσα (και μισώ) την υπερθεωρητική φιλοσοφικοειδή ακαταλόγιστη φυσική. Δεν βλέπω, επίσης, με καλό μάτι το παλιό μου τμήμα, πληθεύουν εκεί οι υπερόπτες και οι σνομπ. Μου φαίνεται αστείο το γεγονός ότι ένα μάθημα κινητών και ασύρματων δικτύων ενός καθηγητή που δεν πολυνοιαζόταν καν για την φυσική ως αντικείμενο (καλός καθηγητής παρά ταύτα) κατάφερε να αναγεννήσει επιτυχώς το ενδιαφέρον στην Φυσική, συγκριτικά με 4 χρόνια προπτυχιακού που προσπαθούσαν να το γεννήσουν εξαρχής.</p><p>Έχοντας πει όλον αυτόν τον πρόλογο, αποφάσισα επίσης ότι η διπλωματική μου θα έχει σύνδεση με το προπτυχιακό μου· τα δύο πεδία θέλω να αλληλοσυμπληρώνονται. Συγκεκριμένα, αναζητώ θεματική (και καθηγητή) που σχετίζεται τόσο με την Μηχανική Υπολογιστών όσο και με την Αστροφυσική (την κατεύθυνση του προπτυχιακού μου) και συγκεκριμένα την Διαστημική Φυσική (το αγαπημένο μου μάθημα από την κατεύθυνση· τέλειος καθηγητής, τέλειο υλικό). Ευτυχώς, ξέρω ότι είναι ένας συνδυασμός στον οποίο το τωρινό μου τμήμα επίσης δείχνει ενδιαφέρον (μέχρι και δορυφόρο εκτοξεύσαμε, λέω αλήθεια!)</p><p>Ώρα να κλείσω. Γεια σας και σας εύχομαι, αν και καθυστερημένα, χαρούμενη νέα χρονιά!</p>"
      }
    },
    {
      "slug": "officially_graduated",
      "hotwords": ["university", "masters", "graduation"],
      "title": {
        "en": "Officially Graduated!",
        "el": "Επισήμως απόφοιτος!"
      },
      "summary": {
        "en": "Goodbye Physics! Hello, new world!",
        "el": "Αντίο Φυσική! Χαίρε, Νέε Κόσμε!"
      },
      "updated": "2024-11-07T00:00:00.000Z",
      "published": "2024-11-07T00:00:00.000Z",
      "author": "Mantis",
      "body": {
        "en": "<p>I have officially graduated from my undergrad with HONOURS! I have also been officially enrolled in my masters! All within one and a half hour from receiving my graduation paper! Not used to <i>such</i> servicing speeds! I am impressed.</p> <p>Masters is going wonderfully. I am on my fifth week now. Learnt tons of stuff, from SystemVerilog to scheduling and memory management in RTOS. Been rather busy, not gonna lie. I have to also cover a few gaps in my knowledge, so my schedule is pretty tight at times. Still, nothing I am not used to!</p> <p>Marching on with confidence!</p> <figure> <img src=\"https://c.tenor.com/GA-_QG_hfPYAAAAC/toad-screaming.gif\" alt=\"toad screaming meme\" width=\"500\"></p> <figcaption>Artist's impression of me turning a new leaf, calmly and collected-ly.</figcaption></figure><p>Oh, also, fun fact: I've now detached the post making from the website making. No need to recompile the whole thing just to add a new post! Technology sure is amazing!</p>",
        "el": "<p>Επισήμως αποφοίτησα από το προπτυχιακό με ΆΡΙΣΤΑ! Και εγγράφηκα στο μεταπτυχιακο! Τάκα τάκα, μέσα σε μιάμιση ώρα από την παραλαβή της βεβαίωσης περάτωσης σπουδών μου! Δεν περίμενα <i>τέτοια</i> ταχύτητα εξυπηρέτησης! Εξεπλάγην!</p> <p>Το μεταπτυχιακό βαίνει καλώς. Πέμπτη εβδομάδα τώρα. Έμαθα τόνο νέων πραγμάτων, από SystemVerilog ως χρονοπρογραμματισμό και διαχείρηση μνήμης σε συστήματα πραγματικού χρόνου. Δεν θα πω ψέματα, έχω σχετικά γεμάτο πρόγραμμα· πρέπει,μάλιστα, να καλύψω και μερικά κενά που έχω. Παρ΄ όλα αυτά, δεν είναι κάτι νέο για εμένα!</p><p>Προχωρούμε εμπρός με αυτοπεποίθηση!</p><figure><img src=\"https://c.tenor.com/GA-_QG_hfPYAAAAC/toad-screaming.gif\" alt=\"toad screaming meme\" width=\"500\"></p><figcaption>Καλλιτεχνική αναπαράσταση της νέας μου αρχής που ξεκίνησα με ηρεμία και αυτοσυγκράτηση.</figcaption></figure><p>Α, για να μην το ξεχάσω: Πλέον οι αναρτήσεις του ιστολογίου είναι ανεξάρτητες της ιστοσελίδας! Δεν θα χρειαστεί πλέον να επαναμεταγλωττίζω ολόκληρη την ιστοσελίδα για μια νέα ανάρτηση! Ζήτω η τεχνολογία!</p>"
      }
    },
    {
      "slug": "godot_remotecar_prototype3",
      "hotwords": ["prototype", "game", "Godot", "code", "physics"],
      "title": {
        "en": "Prototyping mania",
        "el": "Πρωτοτυπομανία"
      },
      "summary": {
        "en": "I wonder if this is another godot prototype",
        "el": "Αναρωτιέμαι μήπως είναι ένα άλλο πρωτότυπο στην Godot αυτό"
      },
      "updated": "2024-09-18T00:00:00.000Z",
      "published": "2024-09-18T00:00:00.000Z",
      "featured_image": "src/assets/godot_logo_big.png",
      "author": "Mantis",
      "body": {
        "en": "<p>I've learnt how to do sky textures, collision detection and programmatic camera angles.</p>            <p>Also, broke the silence with some TOTALLY REALISTIC car sounds.</p>            <p>Here is the video:</p>            <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/HQOq5aOSoLY?si=bEtgCaA0ZGcV8150\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>",
        "el": "<p>Έμαθα να φτιάχνω ουράνιες υφές, την ανίχνευση κρούσεων και προγραμματιζόμενες γωνίες κάμερας.</p>            <p>Επίσης, έσπασα την σιωπή με κάποιους ΥΠΕΡΡΕΑΛΙΣΤΙΚΟΥΣ αυτοκινητοήχους.</p>            <p>Να το βίντεο:</p>            <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/HQOq5aOSoLY?si=bEtgCaA0ZGcV8150\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>"
      }
    },
    {
      "slug": "site_update",
      "hotwords": ["vuejs", "website", "code", "update"],
      "title": {
        "en": "Website updates!",
        "el": "Ενημερώσεις ιστοσελίδας!"
      },
      "summary": {
        "en": "Hear ye, hear ye, it's update time!",
        "el": "Ακούσατε ακούσατε, ώρα για ενημερώσεις!"
      },
      "updated": "2024-09-16T00:00:00.000Z",
      "published": "2024-09-16T00:00:00.000Z",
      "author": "Mantis",
      "body": {
        "en": "<p>Short post today, just want to make a quick update.</p>            <p>Greek language support is now available in the website            and now the website remembers the choices (using cookies) for the options on the panel on the right.</p>            <p>Also, it checks whether your browser has a Greek language preference and sets automatically            the language to Greek, should you not have already have changed the options by using the panel.            Normally, it also checks if you have dark mode on, but for whatever reason it fails to change the mode            with that method. Cookies work properly though.</p>            <p>Finally, the website shows the newest post on the welcome page. Quickly distributed information is what the Internet            is about, after all.</p>            <p>Not gonna lie, the website has made huge steps ever since I first made it. For reference, here is how it looked at the very beginning:</p>            <figure>                <img src=\"src/assets/first.png\" alt=\"website at the very beginning\" width=\"700\"></p>                <figcaption>Small step for man, big step for proper UI design.</figcaption>            </figure>",
        "el": "<p>Μικρή ανάρτηση σήμερα, για γρήγορη ενημέρωση.</p>            <p>Προσέθεσα υποστήριξη της Ελληνικής και δυνατότητα μνήμης των επιλογών στο πλάι (χρήσει cookie).</p>            <p>Επίσης, αν δεν έχουν ήδη δημιουργηθεί cookie, ελέγχει η ιστοσελίδα τις προτιμώμενες γλώσσες του φυλλομετρητή            και, αν η ελληνική είναι μεταξύ αυτών, τίθεται αυτομάτως στα Ελληνικά. Κανονικά ελέγχει αν χρησιμοποιείται φωτεινή ή            σκοτεινή λειτουργία, αλλά για κάποιον λόγο δεν λειτουργεί αυτό σωστά. Τα cookie καλά λειτουργούν όσον αφορά σε αυτό όμως.</p>            <p>Τέλος, πλέον η αρχική οθόνη δείχνει την νεώτερη ανάρτηση. Ταχέως διανεμόμενες πληροφορίες είναι η φιλοσοφία του διαδικτύου, έτσι κι αλλιώς.</p>            <p>Δεν θα πω ψέματα. Γιγαντιαίες προόδους έχει κάνει η ιστοσελίδα από τότε που πρωτοφτιάχτηκε. Να πώς ήταν στην αρχή-αρχή:</p>            <figure>                <img src=\"src/assets/first.png\" alt=\"website at the very beginning\" width=\"700\"></p>                <figcaption>Ένα μικρό βήμα για τον άνθρωπο, ένα μεγάλο βήμα για τον σχεδιασμό διεπιφανειών χρήστη.</figcaption>            </figure>"
      }
    },
    {
      "slug": "translated_wog2",
      "hotwords": ["World of Goo", "translation", "greek", "mod"],
      "title": {
        "en": "World of Goo 2's Greek translation is here!",
        "el": "Η Ελληνική μετάφραση του World of Goo 2 είναι εδώ!"
      },
      "summary": {
        "en": "I finished translating the game in Greek!",
        "el": "Τελείωσα την μετάφραση του παιχνιδιού στα Ελληνικά!"
      },
      "featured_image": "src/assets/wog.png",
      "updated": "2024-09-16T00:00:00.000Z",
      "published": "2024-09-15T00:00:00.000Z",
      "author": "Mantis",
      "body": {
        "en": "<p>It's here! It's finally here! I have finished translating World of Goo 2 in Greek!</p>        <p>It's been a fun endeavour and I hope you will like the result as much as I did making the translation.</p>        <p>You can download the mod <a href=\"https://github.com/xmamalou/wog2-greek.git\">here</a>. Note that currently, the        process of installing the mod is completely manual. Instructions are on the github repo. If you do not understand a step,        don't be afraid to ask in the comments! I will create a proper mod file so people can install the mod through tools like        GooTwool (see <a href=\"https://docs.google.com/document/d/1gWB1PV965roQdAAY-MpFfnTkdwuY1VWXUSschvrIK94/edit#heading=h.eclhwid4t1vd\">this mod doc</a> for details)        when I have a bit more time.</p>        <p>Also note that since adding a new language through mods is a bit iffy, the mod actually replaces Latin American Spanish. Hence,        instead of using the Greek language code (<code>gr</code> or <code>el</code>), it uses <code>es-419</code>.        If you find any untranslated spanish text scattered around, don't hesitate to notify me of it; it's not unlikely that it may have escaped my attention 😅.</p>        <p>Here is a small preview of the translation, showing the main menu, chapter titles and a level:</p>        <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/GTT2MDbq3hw?si=8S88hyKFKQm18jeT\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>        <p>And, as the one and only Sign Painter once said:</p>        <blockquote>Όλοι παίζουμε τον ρόλο μας - We're all in it together</blockquote>",
        "el": "<p>Κατέφθασε! Επιτέλους είναι εδώ! Μετέφρασα το World of Goo 2 (Γλιτσόκοσμος 2) στα Ελληνικά!</p>        <p>Ήταν μια διασκεδαστική εμπειρία και ελπίζω να σας αρέσει το αποτέλεσμα τόσο όσο μου άρεσε η διαδικασία!</p>        <p>Κατεβάστε <a href=\"https://github.com/xmamalou/wog2-greek.git\">εδώ</a> την τροποποίηση. Σημειωτέον ότι, προς το παρόν, είναι        χειροκίνητη η διαδικασία εγκατάστασης. Οι οδηγίες στο αποθετήριο. Αν δεν καταλαβαίνετε κάποιο βήμα,        απλά ρωτήστε στα σχόλια! Όταν έχω καιρό, θα φτιάξω ένα κανονικό αρχείο τροποποίησης για να είναι εγκαταστητό μέσω εργαλείων όπως το        GooTwool (δείτε <a href=\"https://docs.google.com/document/d/1gWB1PV965roQdAAY-MpFfnTkdwuY1VWXUSschvrIK94/edit#heading=h.eclhwid4t1vd\">το εν λόγω αρχείο</a> για περισσότερα)</p>        <p>Επίσης, καθώς δεν είναι εύκολη υπόθεση η προσθήκη νέας γλώσσας, η τροποποίηση         αντί του Ελληνικού γλωσσικού κώδικα (<code>gr</code> or <code>el</code>), χρησιμοποιεί τον Αμερικανοϊσπανικό <code>es-419</code>.        Αν βρείτε αδέσποτα Ισπανικά, μην διστάσετε να με ενημερώσετε! Πολύ πιθανόν να μου ξέφυγαν😅.</p>        <p>Να μια μικρή προεπισκόπηση εδώ:</p>        <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/GTT2MDbq3hw?si=8S88hyKFKQm18jeT\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>        <p>Και, όπως είπε ο ένας και αναντικατάστατος Βάφτης των Πινακίδων:</p>        <blockquote>Όλοι παίζουμε τον ρόλο μας - We're all in it together</blockquote>"
      }
    },
    {
      "slug": "godot_remotecar_prototype2",
      "hotwords": ["prototype", "game", "Godot", "code", "physics"],
      "title": {
        "en": "Another prototype",
        "el": "Κι άλλο πρωτότυπο"
      },
      "summary": {
        "en": "SPEEEED",
        "el": "ΒΡΟΥΥΥΥΥΜ"
      },
      "featured_image": "src/assets/godot_logo_big.png",
      "updated": "2024-09-16T00:00:00.000Z",
      "published": "2024-09-12T00:00:00.000Z",
      "author": "Mantis",
      "body": {
        "en": "<p>Worked a bit more on the prototype</p>        <p>Now the camera zooms in and out based on the \"car\"'s speed. This gives the illusion of great speeds, no?</p>        <p>Added a \"win condition\" as well to better learn Godot's signals and collision detection (and also to learn        how to handle models from programs like Blender; not gonna lie, interoperability between Blender and Godot is        hella cool). Green text        notifies about \"winning\". Red text notifies about the user breaking.</p>        <p>Plus, a bit of lighting for shader practice.</p>        <p>The video:</p>        <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/cpBrpxfv45o?si=ElSgggF-ZKaPdaiU\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>",
        "el": "<p>Δούλεψα λίγο περισσότερο το πρωτότυπο</p>        <p>Πλέον, η κάμερα εστιάζει με τις αλλαγές ταχύτητας. Δίνει την ψευδαίσθηση ότι γκαζώνεις πραγματικά, όχι;</p>        <p>Προσέθεσα και συνθήκη νίκης, να μάθω τα σήματα της Godot, και αισθητήρες κρούσεως (για να μάθω και την συνεργασία μεταξύ Blender        και Godot. Πραγματικά γαμάτη αυτή, έχω να πω).</p>        <p>Λίγος φωτισμός για εξάσκηση στην σκίαση, επίσης.</p>        <p>Tο βίντεο:</p>        <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/cpBrpxfv45o?si=ElSgggF-ZKaPdaiU\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>"
      }
    },
    {
      "slug": "godot_remotecar_prototype",
      "hotwords": ["prototype", "game", "Godot", "code", "physics"],
      "title": {
        "en": "Made a small prototype",
        "el": "Έφτιαξα ένα μικρό πρωτότυπο"
      },
      "summary": {
        "en": "Nothing much",
        "el": "Τίποτε το ιδιαίτερο"
      },
      "featured_image": "src/assets/godot_logo_big.png",
      "updated": "2024-09-16T00:00:00.000Z",
      "published": "2024-09-08T00:00:00.000Z",
      "author": "Mantis",
      "body": {
        "en": "<p>Made a remote car prototype in Godot,        so I can learn the engine and stuff. It can speed up, slow down and go in reverse. Oh, also, it has drag and turns        proportionally to its movement speed.</p>        <p>Here is a video of it. It's nothing much, but it was fun to make:</p>        <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/FGR35cRffyI?si=687MvAL3f7wCsKjm\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>",
        "el": "<p>Έφτιαξα ένα πρωτότυπο κίνησης αμαξιδίου στην Godot,        ώστε να μάθω την μηχανή. Επιταχύνεται, επιβραδύνεται, οπισθοδρομεί και τα σχετικά. Α, επίσης, έχει τριβή και στρίβει        ανάλογα με την τροχιακή ταχύτητα.</p>        <p>Να ένα βίντεο. Τίποτα το φοβερό, αλλά είχε πλάκα:</p>        <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/FGR35cRffyI?si=687MvAL3f7wCsKjm\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>"
      }
    },
    {
      "slug": "thesis_over",
      "hotwords": ["thesis", "university", "physics", "math"],
      "title": {
        "en": "My thesis is OVAH!",
        "el": "ΤΕΛΟΣ η πτυχιακή!"
      },
      "summary": {
        "en": "Yipee! I am a free man (kinda)!",
        "el": "ΓΙΟΥΠΙ! Είμαι ελεύθερος άνθρωπος (περίπου)!"
      },
      "updated": "2024-09-16T00:00:00.000Z",
      "published": "2024-09-06T00:00:00.000Z",
      "author": "Mantis",
      "body": {
        "en": "<p>Yep, you read the title. I have officially finished my undergrad thesis 😎! I am one step closer to receiving        my degree! Now, I only need to pass two courses (technically one, but I am taking another one for extra        grade) and I am finally free and ready to go to my masters!!</p>        <p>Well, that's not <i>entirely</i> accurate. My supervisor still has to look at it and give me a grade, but I am ever so hopeful        everything will go smootly.</p>        <p>Also, it turned out my thesis made my Linear Algebra booklet completely obsolete. Seriously! To give some context: My thesis'        subject was about trying to present Differential Geometry and General Relativity concepts to someone not very familiar with either,        so I could explain Roger Penrose's famous singularity theorem to such an individual (trust me, it ain't as easy as it sounds. Penrose        likes writing <i>densely</i>. I guess it's very fitting with his singularity and black holes work). And one of the sections of my thesis describes some concepts of Linear Algebra (that        are useful for differential geometry),        that almost completely overlap with the booklet. Hence, because the thesis explains them more tidily and properly, I don't think I will        not do the corrections and completions (and translation) I planned for the booklet, and just point to my thesis (if I ever upload it on Github).</p>        <p>All I have to say is that I am beat. It took me approximately 3 months to write the thesis' 74 pages + a whole year of studying Differential Geometry and        General Relativity so I can even be able to write it (oh, did I mention that in the meantime I did a rewrite of it from Word to LaTeX? Yes, I am a masochist).        I think I don't want to see any advanced physics no more. This was filling enough. I am leaving my uni's physics department with a banger (probably not,        but eh, I can dream)!</p>        <figure>                <img src=\"src/assets/the-croods-croods.gif\" alt=\"croods running meme\" width=\"700\"></p>                <figcaption>Artist's impression of me running away from advanced physics forever and ever.</figcaption>        </figure>        <p>Not to say that I didn't enjoy writing it (or physics in general, to be frank) at all. I think General Relativity is a course anybody should take if they want to be called knowledgeable        in physics, and I think my thesis gave me the oportunity to learn things about the field <i>without</i> taking the elective the department offered us (which, honestly, I much prefer),        whilst allowing me to have some form of credential that says \"Hey. This dude <i>did</i> do General Relativity. Trust me, bruh\".        Like, it's no super original Nobel-worthy scientific breakthrough, but I learnt much from it. Not to mention that (I hope) others can learn much from it too.</p>        <p>To slightly (blue)shift the topic (aren't I so funny?), ironically, despite the very formalistic and theoretical nature of my thesis (and the stuff I mostly focused on        all those four years), my masters is quite applied; it's a Computer Engineering masters.        I can't hide that I am kinda excited for it.</p>",
        "el": "<p>Ναι, σωστά διαβάσατε· τέλος η πτυχιακή 😎! Είμαι ένα βήμα πριν το        πτυχίο! Τώρα θέλω άλλα δύο μαθήματα (θεωρητικά ένα, αλλά δίνω άλλο ένα για επιπλέον        βαθμό) και είμαι έτοιμος για το μεταπτυχιακό επιτέλους!</p>        <p>Αν και αυτό δεν είναι 100% ακριβές, καθώς ο επιβλέπων πρέπει να δει την πτυχιακή και να την βαθμολογήσει, αλλά καλά θα πάει αυτό θαρρώ.</p>        <p>Επίσης, πλέον προέκυψε ότι το βιβλιαράκι της Γραμμικής Άλγεβρας το πεπαλαίωσε η πτυχιακή. Αλήθεια λέω! Να εξηγήσω: Το θέμα        της πτυχιακής αφορούσε την παρουσίαση εννοιών Διαφορικής Γεωμετρίας και Γενικής Σχετικότητας στους αμύητους, ουτωσώστε,        να τους εξηγήσω το διαβόητο θεώρημα της μοναδικότητας του Penrose (όχι τόσο εύκολο όσο ακούγεται. Ο Penrose        <i>λατρεύει</i> το πυκνογράψιμο. Επερχόμενο όταν μιλάς για μαύρες τρύπες και μοναδικότητες φαίνεται). Ένα από τα κεφάλαια, λοιπόν, αφορά        την Γραμμική Άλγεβρα (όσα σχετίζονται με την Διαφορική Γεωμετρία) και αλληλεπικαλύπτεται με το φυλλάδιο σχεδόν εξολοκλήρου.        Έτσι λοιπόν, καθώς είναι πληρέστερο και συνεκτικότερο, μάλλον δεν θα κάνω τυχόν διορθώσεις και συμπληρώσεις στο βιβλιαράκι και αντ' αυτού θα προσδεικνύω        την πτυχιακή (όταν την ανεβάσω).</p>        <p>Το μόνο που έχω να πω είναι ότι είμαι 'ξουθενωμένος. Μου πήρε 3 μήνες πάνω-κάτω να γράψω 74 σελίδες, συν ότι μου πήρε έναν χρόνο μελέτης ώστε να μπορέσω        να γράψω την πτυχιακή (το καλύτερο: ξανάγραψα την πτυχιακή από Word σε ΛαΤέΧ κάπου στην μέση της συγγραφής! Ναι, είμαι μαζόχας). Δεν θέλω να ξαναδώ προχωρημένα        θέματα στην Φυσική άλλο πια. Μπούχτισα. Αποχορώ το Φυσικό κάνοντας θραύση όμως (ίσως όχι, αλλά αφήστε με να ελπίζω)!</p>        <figure>                <img src=\"src/assets/the-croods-croods.gif\" alt=\"croods running meme\" width=\"700\"></p>                <figcaption>Καλλιτεχνική αναπαράσταση της απόδρασής μου από την Φυσική.</figcaption>        </figure>        <p>Μην παρεξηγηθώ όμως· μου άρεσε η συγγραφή (και γενικά κάποια κομμάτια της Φυσικής). Εν γένει, η Γενική Σχετικότητα είναι πεδίο ο καθείς πρέπει να εντρυφήσει αν θέλει        να αποκαλείται γνώστης της Φυσικής και νομίζω η πτυχιακή μου υπήρξε ευκαιρία να μάθω <i>δίχως</i> να πάρω το μάθημα επιλογής του Φυσικού (όποιος ξέρει ξέρει), επιτρέποντας παράλληλα        να γράφω στο βιογραφικό «Εϊ, κύριος, ξέρω τι εστί Γενική Σχετικότητα, πίστεψέ με». Δεν είναι καμμιά τρελή Νομπελοέρευνα, αλλά έμαθα πολλά. Και εύχομαι και άλλοι να έχουν αυτήν        την δυνατότητα</p>        <p>Να μετατοπίσω ολίγον προς το κυανό (χαχα, κωμικός ΑΑ είμαι) το θέμα, παραδόξως, παρά την φορμαλιστική και θεωρητική φύση του προπτυχιακού μου και της πτυχιακής, το μεταπτυχιακό        που θα παρακολουθήσω είναι ιδιαιτέρως εφαρμοσμένο· αφορά την Μηχανική Υπολογιστών. Είμαι ενθουσιασμένος, δεν μπορώ να το κρύψω.</p>"
      }
    },
    {
      "slug": "future_of_dragonfly",
      "hotwords": ["Dragonfly", "Godot", "vulkan", "graphics"],
      "featured_image": "src/assets/dragonfly.jpg",
      "title": {
        "en": "The future of Dragonfly",
        "el": "Το μέλλον της Dragonfly"
      },
      "summary": {
        "en": "Thoughts over what I should do with Dragonfly",
        "el": "Σκέψεις επί του τι να κάνω με την Dragonfly"
      },
      "updated": "2024-09-16T00:00:00.000Z",
      "published": "2024-08-28T00:00:00.000Z",
      "author": "Mantis",
      "body": {
        "en": "<p>Dragonfly has been one of my dream projects. I've always wanted to experiment with low level things        related to graphics and develop games of my own. Other game engines that I tried, Unity and Unreal, specifically,        seemed too complex to me, or they were too abstracted and/or didn't offer features I wanted (I know that these        are technically \"me\" issues, but, hey, we all have our pet peeves and weirdness).</p>        <p>For that reason, I decided to make Dragonfly. Dragonfly was meant to be a general purpose graphics and physics        engine that didn't abstract too much over the graphics API, Vulkan in that case. I dedicated a lot of time on that project, trying        to get it exactly the way I had imagined it, and learning everything I could about both graphics and Vulkan. It even went through        a complete C++ rewrite, as the original project was written in C.</p>        <p>Then came the previous month. I had gone on vacation, and didn't take the project files with me (I don't push changes often enough        to the remote repo, so it's often out of date). The repo was too big, couldn't bother waiting for the copy.        To avoid doing nothing for all those weeks, I decided to muck about in other engines. I started        with Unreal. Despite being somewhat fun to work with, I still had the \"overwhelming complexity and too much abstraction\" issues I        had when I had tried it long ago.</p>        <p>I decided to try out Godot next. And I was surprised. In a pleasant manner. Godot had a lot of the features that I wanted Dragonfly        to have, without sacrificing simplicity. It had insanely powerful shading tools (which were one of the reasons I wanted to make Dragonfly)        and, on top of that, the Forward+ mode was using Vulkan!</p>        <p>This got me thinking: Considering Godot existed, Dragonfly was pretty much obsolete from the beginning as a project, as there        was already an engine that took into consideration (almost) all the things I wanted to have in my game engine. For that reason, I decided        to freeze development of the engine for the moment.</p>        <p>This does not mean, however, that I will kill the project. Instead, I am thinking of specializing Dragonfly. One of the features        I wanted for the engine was to be able to simulate Special (or even General) Relativity physics. Thus, I will probably make Dragonfly into an engine        that is dedicated to simulating General Relativity physics -my favourite kind of Physics! Quantum mechanics is a vicious monstrosity. So, instead of it being a game engine,        it will probably be more akin to an engine that aids research or something similar (because, let's admit it, physicists only        bring disaster when they touch computers; just see the mess that is the Internet! Its protocols and their premature release to the wild        were physicists' doing).</p>        <p>Also, I may make it so it will be an engine that uses raytracing, instead of the typical graphics        pipeline (since I mentioned physicists, here is a funny story: Two years ago, when I went to an astrophysics convention as a volunteer, two        guys were quarelling whether one's simulation program should use raytracing for drawing graphics. The other argued that raytracing is \"too expensive and niche\" (!)        and they should use \"this new method, called Phong shading\" (!). Shows how out of date when it comes to computers scientists are).</p>        <p>I should also mention that, even though Godot pretty much makes my project not worth much, I don't think the time I spent with Dragonfly was wasted. If anything, I learnt        so many precious things whilst working on it, that I wouldn't otherwise learn should I immediately start working with an engine. Gaining        knowledge is <i>never</i> a waste of time. Not to mention that the journey of learning new things about graphics is not over yet! It has just began!</p>",
        "el": "<p>Η Dragonfly ήταν ένα από τα όνειρά μου. Η ιδέα να πειραματίζομαι με τα χαμηλοεπίπεδα κομμάτια των γραφικών και να δημιουργώ παιχνίδια        μου κέντριζε πάντα το ενδιαφέρον. Άλλες μηχανές που είχα δοκιμάσει στο παρελθόν, η Unreal και η Unity ονομαστικά, μου φάνηκαν ολίγον περίπλοκες        ή και δεν προσέφεραν τις επιθυμητές για εμένα λειτουργίες (γνωρίζω ότι αυτά είναι προσωπικά θέματα και όχι προβλήματα των ίδιων των μηχανών, αλλά        χουσούρια όλοι έχουμε).</p>        <p>Για τον λόγο αυτόν, αποφάσισα να φτιάξω την Dragonfly. Την σχεδίαζα ως μια γενικής χρήσεως μηχανή γραφικών και προσομοιώσεων, μη υπεραφηρημένη συγκριτικά        με την προγραμματιστική διεπαφή που χρησιμοποιούσα, την Vulkan. Κατένειμα πολύ από τον χρόνο μου σε τούτο το πρότζεκτ, προσπαθώντας να την κατασκευάσω ως επιθυμούσα και παράλληλα        μαθαίνοντας ό,τι μπορούσα περί γραφικών και Vulkan. Ακόμη και ολόκληρη αναγραφή έκανα, από C σε C++.</p>        <p>Και έτσι φθάνουμε στον προηγούμενο μήνα. Είχα πάει διακοπές και βαριόμουν να αντιγράψω τα αρχεία του πρότζεκτ (και δεν είχα ωθήσει τις αλλαγές        στο απομακρυσμένο αποθετήριο, οπότε εκείνο ήταν ανενημέρωτο). Ώστε να μην περάσω τις διακοπές ξυνόμενος, αποφάσισα να δοκιμάσω άλλη μια φορά τις μηχανές        παιχνιδιών. Άρχισα με την Unreal. Διασκέδαζα, το αίσθημα της υπεραφαίρεσης και της υπερπεριπλοκής ήταν παρόν, παρά ταύτα.</p>        <p>Σειρά είχε η Godot. Εξεπλάγην. Με την καλή έννοια. Είχε πολλές από τις λειτουργίες που ήθελα η Dragonfly να έχει, δίχως να θυσιάζει        την απλότητα. Είχε επίσης και πολύ ισχυρά εργαλεία σκίασης (ένας από τους λόγους που ήθελα να φτιάξω την Dragonfly) και, εφ' όλων αυτών,        η λειτουργία «Εμπρός+» χρησιμοποιούσε την Vulkan!</p>        <p>Με έβαλε αυτό σε σκέψεις: Αφού υπήρχε η Godot, τι νόημα έχει να συνεχίσω με την Dragonfly, δεδομένου ότι υπήρχε ήδη μηχανή που        έλαβε υπόψιν όλες τις... ανησυχίες μου. Για τον λόγο αυτόν, αποφάσισα να παγώσω το πρότζεκτ για την ώρα.</p>        <p>Αυτό όμως δεν σημαίνει ότι θα το σκοτώσω τελείως. Αντ'αυτού, σκέφτομαι να αλλάξω οπτική. Ένα από τα κύρια χαρακτηριστικά στην μηχανή που ήθελα είναι        η δυνατότητα προσομοίωσης της Ειδικής (ή και Γενικής, ακόμα) Σχετικότητας. Ως εκ τούτου, στοχεύω κάποτε να την μετατρέψω σε ειδικό πρόγραμμα προσομοίωσης        της Φυσικής της Γενικής Σχετικότητας - της καλύτερης, ήτοι, Φυσικής. Η κβαντομηχανική είναι αίσχος επονείδιστο. Οπότε, αντί να είναι μηχανή παιχνιδιών, θα είναι        πρόγραμμα υποστήριξης σχετικών (χαχα) ερευνών (ας μην κρυβόμαστε, οι Φυσικοί φαίρνουν όλεθρο σαν ακουμπήσουν τους υπολογιστές· τρανή απόδειξη το διαδίκτυο! Τα πρωτόκολλα και        η πρόωρη κυκλοφορία του είναι ευθύνη τους, εν μέρει).</p>        <p>Επίσης, ίσως χρησιμοποιήσω μεθόδους οπτικοποίησης με ακτίνες, αντί της καθιερωμένης γραφικής διαδικασίας (επί του θέματος των φυσικών, ακούστε μια αστεία ιστορία: είχα        πρόπερσι συμμετάσχει ως εθελοντής στο COSPAR και έτυχε να δω δυο λογομαχούντες περί μεθόδων οπτικοποίησης φυσικούς: ο μεν ήθελε να χρησιμοποιήσει την μέθοδο των ακτινών,        ο δε του έλεγε ότι παραείναι «βαριά και απόκρυφη μέθοδος» (!) και μάλλον καλύτερο θα ήταν να χρησιμοποιήσει «την νέα αυτή μέθοδο, την σκίαση Phong» (!). Δείχνει πόσο εκτός τόπου        και χρόνου είναι οι επιστήμονες σε τέτοια θέματα).</p>        <p>Να σημειωθεί ότι παρά την απόφασή μου και την άποψή μου ότι η Dragonfly επισκιάζεται από την Godot, δεν θεωρώ ότι χαράμισα χρόνο με το πρότζεκτ. Έμαθα τόσα πολλά που ειδάλλως δεν        θα μάθαινα, αν επέλεγα αμέσως την «ετοιματζίδικη» μηχανή (δεν το εννοώ σκωπτικά). Η γνώση δεν είναι <i>ποτέ</i> χάσιμο χρόνου. Και το ταξίδι δεν τελείωσε καν· μόλις άρχισε μάλλον θα έλεγα!</p>"
      }
    },
    {
      "slug": "translating_wog2",
      "hotwords": ["World of Goo", "translation", "greek", "mod"],
      "featured_image": "src/assets/wog.png",
      "title": {
        "en": "I'm translating World of Goo 2!",
        "el": "Μεταφράζω το World of Goo 2!"
      },
      "summary": {
        "en": "I am making a mod where I translate WoG 2 in Greek!",
        "el": "Φτιάχνω τροποποίηση μετάφρασης του World of Goo 2!"
      },
      "updated": "2024-09-16T00:00:00.000Z",
      "published": "2024-08-26T00:00:00.000Z",
      "author": "Mantis",
      "body": {
        "en": "<p>World of Goo has been one of my favourite games ever. It was one of my first games ever,        the first game I attempted to complete 100% and the first game (and one of the only few ones) that I have snooped        around the files of and modded. I was so excited when the second one        got announced, and I have been playing it so much! Physics sims will never stop being fun!</p>        <p>When the sequel was announced (you can get it <a href=\"https://worldofgoo2.com\">here</a> btw), the devs requested from the community to help translate the game into        various languages. Sadly, I didn't have much time myself to help (darn university), so I missed an opportunity in translating        the game into my native language, Greek. And sadly, there doesn't seem to be any new opportunity for new        translations in the near future.</p>        <p>Thankfully, it turns out that editing the text of the game is super easy; the texts for        all the current translations of the game are available as human readable files. Not only that, but the fonts        are in a plain ttf format and the game supports Unicode (it was translated in Chinese, Korean and Japanese after all).</p>        <p>Thus, I began working on a translation mod, to make the game more accessible to Greek audiences 👀! I have already extended        the two fonts WoG 2 uses, Twentieth Century and Earth's Mightiest, to support monotonic Greek (since they don't natively        support any Greek characters), and I have translated many parts        of the game!</p>        <p>Even though the game does define an array of different languages, trying to add to those languages seems to break the language        menu and doesn't really add the new language. For that reason, I decided to make my mod simply replace the Latin American Spanish translation of the game.        It's not the prettiest hack, but it works.</p>        <p>I'm having so much fun with the translation so far! I hope you'll like the results as well 😁!</p>        <figure>                <img src=\"src/assets/bigplump.png\" alt=\"something big and plump and juicy\" width=\"700\"></p>                <figcaption>Something big and plump and juicy 😋</figcaption>        </figure>",
        "el": "<p>Το World of Goo είναι ένα από τα αγαπημένα μου παιχνίδια. Από τα πρώτα μου, το πρώτο που απεπειράθην        να τερματίσω 100% και το πρώτο (και ίσως από τα λίγα) του οποίου τα αρχεία έχω εξερευνήσει.        Ήμουν τόσο χαρούμενος και ενθουσιασμένος όταν άκουσα πως ένα δεύτερο φτιάχνεται        και το έπαιζα ως θανάτου! Οι προσομοιώσεις φυσικής πάντα θα είναι τέλειες και διασκεδαστικότατες!</p>        <p>Όταν ανακοινώθηκε η συνέχεια (διαθέσιμη <a href=\"https://worldofgoo2.com\">εδώ</a> παρεμπιπτόντως), ζήτησαν οι δημιουργοί από την κοινότητα        βοήθεια με μεταφράσεις. Δυστυχώς, δεν είχα χρόνο να ασχοληθώ εγώ (φτου πανεπιστήμιο), οπότε έχασα μοναδική ευκαιρία να μεταφράσω το παιχνίδι        στα Ελληνικά. Και δυστυχώς, δεν φαίνεται μια νέα τέτοια ευκαιρία στον ορίζοντα.</p>        <p>Ευτυχώς, φαίνεται πως είναι εύκολη σχετικά η επεξεργασία των κειμένων· τα κείμενα είναι διαθέσιμα ως ανθρωπαναγνώσιμα αρχεία.        Όχι μόνον αυτό, αλλά οι ίδιες οι γραμματοσειρές είναι σε απλή μορφή ttf και το παιχνίδι υποστηρίζει Unicode (μετεφράσθη σε Κινεζικά,        Κορεάτικα και Ιαπωνικά, ούτως ή άλλως).</p>        <p>Έτσι, άρχισα να μεταφράζω το παιχνίδι, για να το κάνω προσβασιμότερο στο ελληνικό κοινό 👀! Ήδη τις γραμματοσειρές τις επέκτεινα, την        Twentieth Century και την Earth's Mightiest, για να υποστηρίζουν Ελληνικά (μονοτονικά, τουλάχιστον) και ήδη κάποια κομμάτια μεταφράστηκαν.</p>        <p>Παρόλο που το παιχνίδι ορίζει πολλές γλώσσες, η προσθήκη δεν είναι τόσο απλή δουλειά και φαίνεται να σπάει το παιχνίδι. Για τον λόγο        αυτόν, η τροποποίηση απλά αλλάζει τα Αμερικανοϊσπανικά. Πρόχειρη λύση, αλλά δουλεύει</p>        <p>Σπάω πλάκα με την μετάφραση! Ελπίζω να σας αρέσει το αποτέλεσμα 😁!</p>        <figure>                <img src=\"src/assets/bigplump.png\" alt=\"something big and plump and juicy\" width=\"700\"></p>                <figcaption>Something big and plump and juicy 😋</figcaption>        </figure>"
      }
    },
    {
      "slug": "vulkan_concepts_part2",
      "hotwords": ["vulkan", "graphics", "rendering"],
      "title": {
        "en": "Learning the basics of Vulkan: Part 2",
        "el": "Μαθαίνοντας τα βασικά της Vulkan: Μέρος 2 (Αγγλικά)"
      },
      "featured_image": "https://upload.wikimedia.org/wikipedia/commons/f/fe/Vulkan_logo.svg",
      "summary": {
        "en": "Talking about the bits and bobs of Vulkan",
        "el": "Μιλώντας για τα γρανάζια της Vulkan"
      },
      "updated": "2024-08-25T00:00:00.000Z",
      "published": "2024-08-25T00:00:00.000Z",
      "author": "Mantis",
      "body": {
        "en": "<p>It has been a long time since I made my first Vulkan post (which you can find         <a href='https://cyber-mantid.xyz/#/blog_post/vulkan_concepts_part1'>here</a>) and I think        it's due time that I wrote the continuation of that post. This time, instead of talking about        the conventions of the Vulkan API, I will generalize and talk about <i>graphics</i> concepts as well        as some other mechanics that concern what Vulkan manages as a whole.        This means that for the graphics part of this post, whatever I will write down will not be Vulkan specific,        but will be applicable to other APIs as well.</p>        <p>So, let's get started already!</p>                <h1>The bureaucratic stuff</h1>        <p>I'll first talk about the concepts which concern less \"hands-on\" things you can do with the API        but rather exist as a way to \"prep\" yourself (or rather, your program) to do those things.</p>        <h2>The Instance</h2>        <p>The first construct somebody has to create is a <code>VkInstance</code>. The role of an instance is not        very clear, at first, but it becomes much clearer if you have some programming expertise. Specifically,        one thing you'll remember -from, probably, countless hours of programmer propaganda- is that \"global states        are evil and stupid\" (maybe not with these exact words). What this means is that we want to avoid our program to have        variables that have no sense of scope, and persist through the entire execution of it. This is due to many reasons,        from making code more modular -and thus easier to debug- to not having to come up with unique or complex variable names because of        simpler ones being already taken (naming things is, afterall, the hardest challenge in programming).</p>        <p>Vulkan itself, being        a responsible and law abiding API, offers its own solution to not having a global scope: Instances! When you initialize        Vulkan, instances act as a \"central\" hub, where information (about what you are making, what debugging features you want -if any-        and what features of Vulkan itself you want to be using, etc) is passed to and stored. What's even neater about this is that        a program needn't limit itself to one instance, thanks to the fact instances are not global. Hence, if you really need to use Vulkan        for a lot of different tasks (which, honestly, isn't usually applicable, but you do you), you are able to create different        intances and thus take advantage of possible optimizations for those tasks. Plus, you also have the advantage of modularity,        and according to what I've heard, modularity is rather hip and cool these days.</p>                <h2>The Physical and Logical Device</h2>        <p>Of course, no self-respecting GPU/graphics API would offer no way to manage GPUs (I guess this makes OpenGL not that        self-respecting). Vulkan is no exception. However, thanks to the low level nature of the API, it doesn't simply \"talk\"        about devices, but rather, distinguishes between two specific \"types\" of devices: Physical and Logical.</p>        <p>Physical Devices are exactly what their name suggests they are: the actual GPUs (or any other Vulkan capable device)        in your system. They contain every single information about it, from how many heaps it has and of what types, to what        features it sports.</p>        <p>But, of course, as with every piece of hardware, GPUs are ugly, fat and unwieldy. Hence, having to deal with a beast        every time we want to do any kind of work isn't going to cut it. As a solution, Vulkan offers a nice little abstraction, called        a <i>Logical Device</i> (although in the API itself, it's always referred to as just <code>VkDevice</code>). A Logical Device        represents only what you will <i>use</i> from a Physical Device, allowing the API to avoid having to initialize unnecessary        features that would really only drag a program down the performance hell-hole.</p>        <p>Similar to instances, however with much more usefulness, this time around, Vulkan allows you to create multiple logical        devices <i>per instance</i> and even multiple devices <i>from the same physical device</i>. This can be really helpful, since        one can separate purely computational work from purely graphical work on their own devices, for example, without needing to        set up any synchronization, if they don't really need those two to interact with each other.</p>                <h2>The Layers and the Debugger</h2>        <p>Lowlevel-ness doesn't come with a cost. Having to get rid of all those bits and bobs that manage all the ugly stuff        for you means that there's really no middleman to inform you about what may go wrong. Thankfully, all is not lost.        Instead of having the API act as the middleman, Vulkan offers something known as <i>layers</i>. Layers are little pieces of        software that run in parallel with your program -if you want them to- and report on various errors (or other information) concerning your        usage of Vulkan. Similarly to everything else with Vulkan, there's no \"layer to rule them all\" and you have a multitude of        layers, all catering to different debugging needs. In fact, it's not uncommon for \"third parties\" (in respect to the provider        of the SDK which contains the Vulkan API) to provide their own layers, usually for debugging features that relate to        services they provide (for example, in my machine, I have layers related to Steam and OBS).</p>        <p>Of course, layers themselves just check for and \"report\" errors, but as they are meant to be plain and platform independent, they        really don't do anything more. This is where the Debugger (or more accurately, the Debug Messenger) comes in. The debugger's        job is to gather all the errors, warnings and other info that the layers report and relay them back to the application that        is using those layers (duh, it's literally a messenger). Usually, the messenger itself will be nothing more than a fancy printer to standard output, but Vulkan        gives much more flexibility on what it can be (you could, for example, pass its information to a GUI application and have a much        more fancy messenger. The sky is the limit!).</p>        <p>Note that debugging utilities are an extension to Vulkan (<code>VK_EXT_debug_utils</code>), so you need to enable them whilst creating an instance. Also, there        are many more debugging features that this extension provides, such as object taging and command labeling, but I won't really        go into that much detail over them.</p>                <h1>The Nuts and Bolts</h1>        <p>So, you've created an instance and have reserved a device. But you are still not ready to do serious work. Remember,        Vulkan is a low level API, and thus requires that you know the thing you are working with; in this case, with the GPU.</p>                <h2>Queues</h2>        <p>How does a CPU execute work? It consists of threads that retrieve instructions from memory and execute them independently        from each other (at least in theory). Similar to that, in order for a GPU execute work, it offers <i>queues</i> on which        that work is submitted to. However, queues are not exactly the same as CPU threads.</p>        <p>For starters, queues have a \"type\". Specifically, they can be either <i>graphics</i>, <i>presentation</i>, <i>        compute</i> or <i>transfer</i> queues. A type of a queue specifies what work it can execute. What those types specifically entail        seems intuitive enough:</p>        <ol>            <li>Graphics queues are able to execute graphics pipelines (duh).</li>            <li>Presentation queues know how to talk with both the OS and a display device so they can present an image to the user.            This may seem like an artificial distinction from the graphics queue, but it's a rather important one! There are plenty            of GPUs that are not meant to \"show stuff\". Sure, they are usually non-commercial and used for niche applications, but            Vulkan isn't a GPU-ist API and includes and considers them as well. Fortunately for you (at least assuming so), graphics            queues on most commercial GPUs also double as presentation queues.</li>            <li>Compute queues are able to execute compute pipelines (how surprising!). It's not uncommon to find only these kinds of queues            in GPUs meant for mainframes or other number crunchers, that don't really care about showing anything fancy to someone (except their            big numbers, of course).</li>            <li>Transfer queues are all about memory operations. This includes operations that seem more fitted to be done by graphics queues,            like image blitting (copying parts of an image to another image) or mipmap generation (mipmaps are versions of an image of smaller resolution,            useful for rendering optimizations). But such operations are purely memory trasnfer operations, and don't really require any graphics            algorithms.</li>        </ol>        <p>Second, thanks to the extremely parallel nature of GPUs, work is executed in parallel not only across queues, but also within        a single queue. Of course, someone may ask \"Why have multiple queues then?\". The answer is simple: whilst the default behaviour        of a queue is to execute submitted work in parallel, it is still meant to execute work that is, in some way, related to and dependent        to each other. Not only that, but it really doesn't make sense, in the first place, for work to be executed sequentially within a queue (GPUs are        bad with that anyways), but rather in a more asynchronous manner. What is meant with that will be clear when I'll talk about synchronization        in Vulkan.</p>        <p>Note that queues in Vulkan are grouped into families; queues of the same family share the same type. Also, when creating        a logical device, you need to specify what families you want to use and how many queues from each family you need, keeping        in line with a logical device's philosophy of \"using only what you need\".</p>                <h2>Command buffers</h2>        <p>Okay, you now have a good instruction follower. What do you do with it?</p>        <p>You <i>could</i>, theoretically, submit instructions directly to the GPU, but think about it for a second; with a CPU, do you submit to it        the assembly instructions yourself? No! That'd be absurd. And probably boring! Instead, you write a program in some language, and have it        be translated into machine language to be executed at a later point.</p>        <p>Command buffers are Vulkan's version of \"I write a program in a high level language and have it compile in machine language\". One        \"writes\" a program in the higher level C API (using <code>VkCmd</code> functions) and in the meantime, the API creates a buffer where it        pushes the GPU instructions on and performs any optimizations it sees fit.</p>        <p>Of course, this also means that, when recording a command buffer, what seems sequential is, in fact, not at all. So one has to keep        in mind that, in the majority of cases, you really don't have to abide to a strict hierarchy of commands; two commands that come one after        another in the recording phase are not guaranteed to execute in that order.</p>        <p><i>Side note:</i> if the idea of command reordering seemed already weird to you, here's another weirder thing: Even sequential CPU code may,        in fact, end up being non sequential! Compilers are free to order CPU instructions as they see fit, as long as they can keep the façade of sequentiality        (sequence? sequentialness? I dunno, English is weird). This is done because, often, many optimizations can be done, especially such optimizations        pertaining to memory access.</p>        <p><i>Another side note: Something I should mention about command buffers is one important property of their commands: the stage. The stage        essentially tells Vulkan what part of the pipeline the command is responsible for. Note that saying \"part of the pipeline\" can be misleading        as you may think of graphical pipelines (or even compute pipelines). But reality is that the stage has to do with <u>any</u> operation        taking place in a command buffer, including transfer operations that are not related or bound to a graphics or compute pipeline.         Even the beginning or ending of a command buffer are also considered stages. Stages are important to remember, as they are an important        concept for synchronization.</i></p>                <h2>Memory</h2>        <p>Of course, a device is not worth much if there's no way to <i>store</i> things in it, even if for just a short amount of time. Thankfully for        us, devices have memory! Specifically, Vulkan divides GPU memory into two big categories: Local memory and Shared memory. Both are self-explanatory:        the former concerns memory that is on the GPU itself, whilst the latter memory that is shared with the host itself</p>        <p>The divisions don't end there, however. Both of these categories divide memory into chunks; \"heaps\" per the terminology. And those \"heaps\" are further        divided into \"types\". Now, for the types of heaps, I used the word \"divided\" very loosely; in reality, a heap's memory isn't divided any more.        Instead, types represent different \"interpretations\", so to speak, of the heap. Different types can represent different features of the heap and offer        different possible optimizations. And, of course, a heap can have multiple types, hence the word \"divided\".</p>        <p>Important thing to remember when requesting memory from Vulkan is that you request for a type, not a heap. Not only that, but you cannot infinitely        allocate memory; most devices support only a limited amount of <i>simultaneous</i> allocations (usually in the order of thousands). For that reason, instead        of just allocating memory when necessary, you allocate bigger chunks of memory, which you then divide for various uses (this is similar to using heap memory        on the host system; in general, we prefer infrequent big allocations to frequent small ones, as heap allocation is, generally speaking, a slow process.        If you've seen an implementation of <code>malloc</code> and co in C, or general purpose allocators in a language like Zig, you may have noticed that they too allocate        bigger chunks of memory than what the programmer requested, exactly to avoid costs of frequent small allocations).</p>                <h2>Buffers and Images</h2>        <p>As I said in the previous section, it's common practice to reserve big chunks of memory for multiple purposes, instead of small chunks for a singular purpose.        Probably, this may arouse woes from the memory management        haters. \"Ugh, so we need to keep track of what's where as well?\", they'll say, \"No sir, this is a crap API\". Don't worry haters! Vulkan has got you covered!        Instead of working directly with memory, it offers two storage primitives which can bind to and abstract over memory: Buffers and Images.</p>        <p>Buffers are the simplest primitive. They represent simple, contiguous places in memory. Nothing more, nothing less. They work exactly the same        as we'd expect a (raw) pointer in a programming language to behave. In fact, if you have GPU memory that the host can see, you can use a buffer        just like a common pointer. Most        of the time, however, buffers will be written to by command buffers and compute shaders.</p>        <p>Images are more involved and that's due to their purpose. Whereas buffers are simply meant as generic storage, images are specifically made        to store graphical data (i.e. images). This means that they have lots more structure than buffers. For starters, images have the concept of dimensions:        you can have images with 1, 2 or even 3 dimensions. They also have layouts: Vulkan can reorder the data in an image so it can be optimized for        different operations that can happen to it. The orders said data can be in are known as layouts. There are different layouts depending on the        purpose: there's a layout when writing colour data to an image, a layout when transferring general data, a layout when writing depth data etc.</p>        <p>Images also come with three graphics related settings: formats, samples and mipmaps. Since images tend to hold colour data, formats determine the        colour space and general representation of that data.</p>        <p>Samples, on the other hand, determine how many samples per texel (a texel is for an image what a pixel is        for a monitor: the smallest unit of the image) an image can have. Samples are used so we can reference decimal positions on an image; normally,        since there is a natural number amount of texels in an image, that means that, under normal circumstances, one could only refer to a position on an image        using only integers. However, sampling allows us to refer to a position on an image using abitrary float numbers, by essentially \"averaging\" the texels        that are near the point we chose.</p>        <p>Mipmaps, despite the funny name, have quite an important purpose. Mipmaps are \"recursively smaller pictures\"; by that, I mean the following:        mipmaps are divided into levels; each level is half the resolution of the previous level and level 0 is the original image. Hence, a level 3 mipmap        would be \\(2^{-3}\\) times the original resolution. Mipmaps are used when rendering things that are \"far away\": they enable the GPU to do less        work for things that are not as easily seen + they can help reduce Moiré patterns (the weird line effects you see pop up on screens, usually when images        of small grids show up, or similar patterns). Another cool use of mipmaps is as a cheap way to implement reflections.</p>        <p>NOTE: Both Buffers and Images have what is known as <i>views</i>. They are pretty self explanatory: they offer a view onto a part of a storage resource,        which is quite useful for shaders. Image views can also change the format of an image or even swizzle colours.</p>                <h1>Law and Order (of execution)</h1>        <p>As it is made apparent from the previous section, Vulkan is perfectly happy to mangle, by default, commands submitted to a device's queues. But,        of course, this is not always desired. Thankfully, Vulkan has some tools for us that help us <i>synchronize</i>. Specifically,        the API offers 4 synchronization primitives (note that extensions can add more of them): semaphores, barriers, fences and events.</p>                <h2>Semaphores</h2>        <p>The semaphore is the first important kind of synchronization primitive. Semaphores achieve the synchronization of command buffers submitted to the same queue; they        block the execution of a command buffer so it can wait for another command buffer to finish. But here's the best part: you can explicitly specify <i>exactly</i>        which stage (remember them from the paragraphs about command buffers?) of a command buffer needs to wait on which command buffer. This        ensures that command buffers won't waste precious time waiting on something, even though they can perform work that doesn't depend on that        something.</p>                <h2>Barriers</h2>        <p>Of course, we don't want to synchonize command buffers with each other only, but we also want to be able to have a command buffer not mangle        itself where it shouldn't. For that, barriers come to the rescue. Barriers tell the API how to organize        a buffer's commands based on <i>memory accesses</i>.</p>        <p>If you have seen atomics in other languages, you may see where this is going. The principle of synchronization is exactly the same here. If you haven't,        you may think that ordering based on memory access is counter-intuitive. But, in fact, it frees our hands immensely; let's look at it through the model of threads.        Assume you have thread A and B, and those do their own thing perfectly separate from each other. But, at one point, A has to write something to memory M, and B has,        afterwards, to read from M. Of course, one could simply block B until A has finished writing to M, if B is at the point of reading alrady, but this is extremely wasteful!        Can't we just do other work whilst we wait for A to write?        Remember, even in CPU code, instructions get reordered! So, the solution is the following: Instead of wasting B's time by having it do nothing, just make sure that every instruction        reading M comes <i>after</i> A has finished reading. Before that point, you are free to put whatever instruction doesn't depend on M's result, allowing B to        do work, whilst waiting for A to write.</p>        <p>The idea in Vulkan is the exact same. Instead of blocking commands on a buffer from executing, and thus wasting precious GPU time, we instead make sure that only        the order of instructions which depend on each other is as it needs to be, and we happily ignore the chaos of every other instruction.</p>        <p>Barriers have a more fine-grained set up than just what memory access they are supposed to synchronize. Specifically, they are split into        three types: buffer barriers, image barriers and global memory barriers. The first two have to do with the storage primitives Vulkan        offers. Image barriers are especially important, because they ensure images are in their proper layout.         The last is a more generic barrier, which orders <i>all accesses</i> on memory        operated on by a buffer, regardless of how (or even if) it is operated on. This may sound like a bad option then (for example, if you have        commands that operate on one chunk of memory, and other commands that operate on some other chunk, they will need to wait for each other,        even if they don't really need to), but reality is that        a lot of times, command buffers don't really operate on such fine-grained memory. So, in many cases, buffer and global memory barriers are        interchangeable.</p>                <h2>Fences</h2>        <p>Synchronizing GPU work is good and all, but a GPU doesn't live in a vacuum (probably fortunately for itself, vacuums are cold and electronics        hate too much cold)! Hence, it also matters whether we can make the GPU and the host behave nicely with each other. For that reason, we use <i>Fences</i>.        Fences are quite simple conceptually. Each batch of command buffers submitted to a queue is associated with a fence. A fence has two states: the unsignaled and the        signaled state. When a batch is submitted to be executed, the fence is on the <i>unsignaled</i> state. Once that batch has finished        executing, the fence is put on the <i>signaled</i> state, which tells the host (at least if the host is honest and actually checks the fence's state)        that it can do whatever it waited the batch to finish for.</p>        <p><i>Side Note</i>: In a sense, a fence works like a fuse in your electric box; by that, I mean that once it's signaled, you need to explicitly reset it        to the unsignaled state, otherwise it cannot be reused (similar to how you need to turn up a fuse on the electric box if it turned down, or else        you will get no power).</p>                <h3>Events</h3>        <p>You may have noticed a pattern with the previous synchronization primitives; the first two describe a coarse and a fine GPU-with-GPU synchronization, respectively.        The third describes a coarse GPU-with-host synchronization. So, it is only natural that there is a finer way to synchronize host and GPU; events provide        that way. The idea of how they work is exactly the same as with fences; they have a signaled and unsignaled state, and the        host can check when an event is signaled. The difference here is that command buffers are able to explicitly signal events and        are able to wait for events to be unsignaled by the host.</p>                <h1>The real deal</h1>        <p>So, now that you told Vulkan what to use and how to use it down to the last bit, it's time to start talking business. Graphics business!        This is probably the biggest and windiest part of Vulkan, and naturally, it comes with a lot of pain; for absolutely free, no less! I should        probably start by those parts that are directly related to the relationship between a graphics application and the host that runs that application;        the <i>surface</i> and the <i>swapchain</i>.</p>                <h2>The Surface</h2>        <p>When you render graphics, where do you want them rendered to? Most likely a window (or using exclusive fullscreen, if you are mad). So, no matter        all the fancy effects you have cooked up to make the best image possible, you'll need to make sure that there is such a window to present that image to.        There is a problem though: Windowing is platform specific. Vulkan knows nothing about any platform, since it's meant to be platform agnostic. In other        words, there's no direct way for Vulkan to talk with windows, at least not without having to introduce platform specific interfaces.</p>        <p>The solution to that is        the following: Isolate all the platform specific code into a singular construct, which will abstract all that and hide it from the rest of the API. That construct        is called a <i>surface</i>. Thus, a surface is a representation of a window, that doesn't expose any of the specifics of how the window is made. Hence        the rest of the API can plaster anything it wants onto it, without having to worry about platform dependent tomfoolery.</p>        <p>REMEMBER! Similar to other graphics stuff, Vulkan does not assume that all GPUs (or in this case, OS) are capable of showing stuff \"on screen\".        Hence, Surfaces are an extension to the API, and not part of the core API.</p>                <h2>The Swapchain</h2>        <p>Okay, now you have something that will allow you to show your images on the screen. Here's the problems, however: First, Vulkan        still doesn't know what exactly to do with the surface. Only thing it knows is that it's \"a place to show stuff on\". Second, It's not necessary that        your rate of producing images will match that of the refresh rate of the screen. This presents with an issue: If your image rendering rate        is higher than that of the refresh rate, and you just immediately rush your images to the surface, you will inadvertedly cause what's known as        \"tearing\": The screen won't be able to show the already submitted picture in time, and instead will show part from the newly submitted picture.        This is what causes a \"tear-like\" effect, where the parts of two different images are on screen.</p>        <p>To mitigate both of these issues, Vulkan adds a new middleman to the flock (if you haven't guessed already, it loves doing that): the Swapchains!        Swapchains reveal their purpose from the name alone; they are chains of images to be swapped to the surface (really straightforward, no?).</p>        <p>Specifically, swapchains are constructs that are owned by the operating system, and represent \"pools of memory\" where an application can submit        images to that are meant to be presented. In some sense, they work exactly like conveyor belts. To give an analogy: imagine a dark room (the kind of        dark rooms where photos get developed). In this dark room, the one developing the photos is you (or the application). On top, you have a conveyor belt        with pegs from which you can hang your photos. That conveyor belt is the swapchain, and the total pegs on it represent the amount of images the swapchain can hold.        Each time you develop a photo, you can hang it to a peg (you fill an image of the swapchain with data). After that, you can move the conveyor belt forward: You tell the OS to present the next image        of the swapchain to the surface (note that \"the next image to be presented\" is not necessarily the one you just rendered). Meanwhile, another peg, probably        with another photo on it, arrives back at the dark room. You take that photo off the peg (you clear it) and hang another one (you replace its contents with        a newly rendered image).</p>        <p>To not lose ourselves too much with the analogy, the whole jist of the swapchain is that, from one side, it provides a Vulkan-native way        to transfer graphics data to, and from the other, it allows the application to render as many images as it finds        fit, <i>without</i> necessarily disrupting what is already being shown to the user. If you've guessed already, it is the construct that enables <i>Vsync</i>.        Technically speaking, though, Vsync refers to one mode from what is known as presentation modes. The most common ones are the following:        </p>        <ul>            <li>Immediate mode: In immediate mode, images are presented as soon as they are available. This is equivalent to setting vsync off.</li>            <li>FIFO (First in, first out) mode: In FIFO mode, an image will not be presented but at the moment the screen refreshes (i.e. there is a vertical            blank), even if it's available.            This is the classic Vsync mode.</li>            <li>Relaxed FIFO mode: A spin on the previous mode, Relaxed FIFO will only wait for the first vertical blank to present an image. If, however, there            was no image to present at that point, but a new image was made available afterwards, Relaxed FIFO will immediately present it to the screen.            This is a mode that combines the \"best\" of both Vsync and no Vsync: under normal circumstances, it makes sure that there's no tearing; however            if an application, for whatever reason, was too late at delivering new images, it just hastily presents the next image. This does mean, however            that tearing may appear.</li>            <li>Mailbox mode: What if, now, our application is super fast at rendering images (because we're just <i>that</i> good)? What wasn't mentioned            with the FIFO modes is that once you have queued a second image for presentation, if you attempt to queue another one, that request will block            the requesting thread <i>until</i> the image that isn't presented yet is actually presented. This is, obviously, not good, since that means            our app wastes precious time doing nothing. For that reason, Mailbox mode comes to the rescue: every time you queue a new image to be presented,            mailbox mode will <i>replace</i> the image that hasn't been presented yet to the screen. This is often known as <i>triple buffering</i>.</li>        </ul>        <p>Of course, someone may ask \"Why not use Mailbox mode all the time, then?\". For two reasons: First, Mailbox mode may not always be available.        In fact, the Vulkan specification demands that <i>only</i> immediate mode is guaranteed to be available. Second, FIFO and Mailbox only really        enable vsync. You cannot do custom refresh rates using these. For that, you need to use immediate mode and instead of relying on the swapchain        to present images whenever necessary, you instead keep track of the time between submits yourself.</p>        <p>One last thing: The amount of images you have on your swapchain do not directly correlate with the modes. You can have as many images as you like        (within the allowed device limits). The modes simply decide the \"swapping\" behaviour. Not only that, but even though images on the swapchain are represented        with an index, like an array, that index does not do much other than simply identify the image; the swapchain is not forced to present images on order of index.</p>                <p></p>        <p>Okay, so now we know what we need to do to make the OS acknowledge our beautiful pictures. But how do we actually make said pictures? The last Vulkan constructs        I will present in this post are all about that: The Pipeline, the Renderpass and Supbasses, and the Framebuffer!</p>                <h2>The Pipeline(s)</h2>        <p>If you think about it, creating a picture out of a 3D model is quite a parallelize-able process. Each pixel that is to be rendered rarely,        if ever, depends on the other pixels that are being rendered (note, effects like blurring, where the pixel is given a colour that is averaged        from the colours of all the pixels near it, isn't really a case of dependence of the pixels that are being rendered. Instead, this is a post processing        effect that takes the image to be blurred as input; no dependence pops up between the different <i>new</i> pixels)</p>        <p>Not only that, but going from 3D model to painted pixel is, thankfully, quite easy to break down into stages. This means that rendering images        is something that can be quite easily pipelined! Hence, one of the core parts of any graphics application is the so called <i>graphics pipeline</i>,        a construct which represents all the stages that go into rendering an image</p>        <p>But how does the graphics pipeline exactly work? First, it starts with what's known as the <i>vertex assembly</i>. At that point, the GPU        is fed data that represents the vertices of a model, i.e. points on space. That space, however, is not \"the world\", the place where all of our 3D models        live in; instead, it is what is known as the \"local\"        space, i.e. the space that contains only the model that is being rendered and where the locations of the points of that space are relative to that model.</p>        <p>After the vertex assembly, the pipeline moves onto the first shader state: <i>the vertex shader</i>! Shaders are -besides tools for making aesthetic        Minecraft screenshots- stages-programs that are fed to the GPU by the programmer (similar to command buffers, in a sense, but more versatile). In ye olde days,        pipelines lacked such stages; instead, everything in a pipeline was fixed. The advancements in GPU technology and graphics APIs managed to make some of the stages        much more customizable. The vertex shader is one such stage: It allows the programmer to define exactly how to place a model into world space (i.e. \"the world where everything lives in\")        -which is nothing more than an intermediate space that only really matters to the programmer, not the GPU- and from there onto camera space (i.e. it transforms everything in        world space in such a way as a camera would see the world). Note that the camera space isn't limited to the window that an image is being rendered to;        instead, it represents the plane which the window is part of. The vertex shader is where you would usually make final transformations to an object (like applying displacement        maps and all that). It        also allows for customizable camera projections (perspective and orthographic). Not to mention that smart use of the vertex shader enables one to make        non Euclidean geometry graphics! (NOTE: Contrary to popular belief, \"non Euclidean\" doesn't mean \"portals!\". It means that the shortest path on space        is not a straight line. Rather, it's some other line altogether).</p>        <p>After the vertex shader, there's two optional shader stages: the Tesselation shaders and the Geometry shader. If someone uses those        stages, then the vertex shader generally stops being responsible for transforming a model from local space all through to camera space (that        responsibility is passed down to either of those two stages),        and only handles any transformations that are meant to be done on a model. The tesselation shaders,        as the name suggests, are responsible for generating new vertices from the old ones, based on programmer-defined conditions. They are used        for subdividing meshes further, keeping the original model light, and without introducing load to the CPU (which would be the one to subdivide        the model, should the tesselation shaders not exist). The conditional nature of those shaders also means they are useful for LoD's        (Levels of Detail). The Geometry shader, on the other hand, is responsible for generating geometry from vertices; hence, it's useful for creating        effects such as explosions, where a model would become fragmented.</p>        <p>After those stages, the GPU generates the primitives (i.e. triangles) based on how the vertices were ordered when they were fed to it, and then it moves to the next        stage, which is a fixed one: Culling and Clipping. Culling is the process where the GPU throws away any primitives that, for a fact, it knows they will not        be seen (because even though they are in camera space, they fall completely outside the portion of the space that is on the window). Clipping is the process        where anything that has survived, but still has some parts falling outside the window, is transformed so as to discard the portion that the window doesn't see.</p>        <figure>                <img src=\"src/assets/clipcull.svg\" alt=\"culling and clipping\" width=\"327\" height=\"308\"></p>                <figcaption>Fig. 1: Culling and clipping.</figcaption>        </figure>        <p>The next stage is rasterization: The GPU turns the primitives into fragments. Fragments are \"potential pixels\"; in other words, they are        actual pixels of the image to be rendered on the window, that, however, it is possible that they will be disgarded later.</p>        <p>When a fragment is generated, it enters the next stage and the last programmable stage: the fragment shader. The fragment shader        is where the programmer can go all wild with colouring and shading effects. It's essentially the same stage that you see in material        editors in game engines or 3D modelers; in fact, it's not rare for either to allow you to write up your own shader for materials instead of using their own        interface.</p>        <p>After a fragment has been painted on, various other operations take place, on the last stage of the pipeline. Those are fixed and concern things        like colour blending and depth testing. It's at that stage where the GPU will decide whether to keep a fragment or discard it, probably because        there's something else on the image that is \"in front\" and thus would cover it (so, it makes no sense to put that fragment in the final image).</p>                <p>Something you should note is that pipelines are not actual commands, unlike command buffers; rather, they are more akin to \"diagrams\" that describe a job        the GPU must do. In fact, pipelines allow the host to pass custom parameters to shaders, so as to alter their behaviour slightly. Those parameters        are grouped in constructs known as descriptor sets and push constants. This is a life saver, since pipelines are usually quite expensive to build,        which means that instead of building a pipeline per object, we can instead build a pipeline per material (or per material group), which is a significantly        lower amount of pipelines to be built, and simply        change parameters for every model we have to render.</p>        <h2>The Renderpass and the Subpasses</h2>        <p>As mentioned above, pipelines are grouped per material. However, this presents with the following issue: How will all the pipelines know how to work with each other? Wouldn't a pipeline just cover whatever another        pipeline has already created? To solve this issue, Vulkan offers a construct known as a <i>Renderpass</i>: A renderpass groups all pipelines        that a rendering operation will use, outlining a common place where they can render to, but also check if they should render at all. It's through        the renderpass that operations like, for example, depth testing work: a renderpass defines a common depth attachment, where the different pipelines in it can        check whether a fragment should be discarded (because they are behind something that was already rendered) or kept.</p>        <p>Renderpasses can be further divided into subpasses, separate rendering units, that is. Those subpasses are able to define complex rendering        operations, since one can define complex dependencies between each other; they are oftentimes used for operations like deferred shading or        even post processing effects.</p>        <p>One issue with renderpasses is that they are quite cumbersome to set up and usually        require an \"a priori\" preparation of the rendering system, as they are immutable (like most things in Vulkan). In response to that, more recent developments in the API have        made possible to circumvent the renderpass altogether and instead define rendering operations dynamically, within command buffers.         However, this comes with a catch:        many GPUs or other graphics devices, especially those in mobile phones, are not very good at handling dynamic rendering operations and are        rather more optimized with renderpasses in mind. Hence, you should just pretend that dynamic rendering operations are not a thing,        lest you really want to limit the devices your application can run well on.</p>                <h2>The Framebuffer</h2>        <p>Of course, the renderpass only represents a \"mental\" idea of how pipelines are grouped and organized together. They don't really        allocate any space where the rendering operations can actually take place. For that, you need to explicitly define a framebuffer, a collection        of image views (remember those? From the Buffers and Images section?) that agree with what the renderpass has defined. It's the framebuffer        where you use views of swapchain images so you can actually render images to later present to the surface.</p>                <h1>Conclusion</h1>        <p>So, that's all I have to say, to be honest. It took me ages to make the sequel of the first post, but I hope it was worth it. Of course,        all of the above does nothing more than scratch the surface of what Vulkan actually is and is capable of. However, bundled with the previous post as well,        this should give you a rather nice heading to start your Vulkan journey from</p>        <p>By the way, if you haven't known already about it, I hugely recommend the official Vulkan Programming Guide, by Graham Sellers. It's an excellent        and quite comprehensive book, and I am sure it will be of immense help when learning Vulkan!</p>"
      }
    },
    {
      "slug": "cpp_operator_overload",
      "hotwords": ["overloading", "cpp", "operators", "code", "math"],
      "title": {
        "en": "When to overload C++'s operators",
        "el": "Πότε να υπερφορτώνεις τους τελεστές της C++ (Αγγλικά)"
      },
      "featured_image": "https://www.svgrepo.com/show/452183/cpp.svg",
      "summary": {
        "en": "Overloading is fun, but should be handled with care",
        "el": "Η υπερφόρτωση έχει πλάκα, τουλάχιστον με φειδώ"
      },
      "updated": "2024-05-13T00:00:00.000Z",
      "published": "2024-05-13T00:00:00.000Z",
      "author": "Mantis",
      "body": {
        "en": "<p>One of C++'s core features is that of operation overloading.        The premise is simple yet powerful; for almost all operators the C++ specification defines, you can override their behaviour according        to your needs. A simple example:</p>        <pre>    class MyClass;\n    MyClass myObject;\n    \n    MyClass operator + (const MyClass& obj1, \n                        const MyClass& obj2) {\n        \\\\ Function body here\n    }    </pre>        <figcaption><i>NOTE: The space between the word <code>operator</code>        and the operator itself is not necessary, just done for aesthetical reasons.</i></figcaption>        <p>However, whilst it's a powerful feature, it comes with a catch: Since those        operators have a specific function (pun intended?) ingrained into our minds        having an overload perform a massively different function will, inevitably,        lead to confusing code and inability of someone reading over it to completely        understand what is going on.</p>        <p>In this post, I am going to talk about what I think someone should do (and not do)        when overloading operators in C++.</p>        <h1>Which operators are overloadable, anyways?</h1>        <p>The C++ specification has quite a few operators defined and most of them are        overloadable. In fact, when talking about what and what cannot be overloaded, it's        easier to talk about those that cannot be. Specifically, the following are not overloadable:        <pre>    ::  \\\\ Scope operator \n    .   \\\\ Member access operator \n    .*  \\\\ Pointer to member access operator \n    ? : \\\\ Conditional operator     </pre>        <p>Whilst even this may seem kind of limiting, the philosophy behind overloading        operators I will present below will show that, in the end, it's really not that        big of a deal.</p>        <p>Also note that to overload a nonmember operator, at least one of the parameters        it takes has to be a user-defined type.</p>        <h1>General rules of thumb when overloading.</h1>        <p>        <ul>            <li>Overloaded operators should not have side effects. In other words, they            shouldn't be able to change something on your program that lies beyond the            local scope they are executed in. No global variable changing, no initialization,            nothing like that. Sole exception is the function call operator (<code>()</code>).</li>            <li>Overloads of assignment operators should always return a reference to the left operand</li>            <li>Similarly, overloads of logical and relational operators should always return a boolean value.</li>            <li>Conversion operators should do nothing more than convert the argument to            the target type. They shouldn't modify the object.</li>            <li>Overloaded operators should, in general, mimic the behaviour of the original operator or            at least try to comply with people's intution on how an operator should behave.</li>        </ul>        </p>        <p>            I will now go over specific conditions per operator that, I think, should be met when it comes to            overloading said operators        </p>        <h2>The basic arithmetic operators (<code>+</code>, <code>-</code>, <code>*</code>, <code>/</code> and <code>%</code>)</h2>        <p>            When it comes to the four basic arithmetic operations, people's main intuition about them is that whatever            they operate on should behave \"like a number\". Mathematics actually has a name for this behaviour; we say that the operands            form a <i>field</i>.        </p>        <p>Thus, one should overload those those four operators if they intend that their operands be of the same type, let it be \\(T\\)        and they -the operators- return that same type. In other words, the declarations of the overloads should look something like this:</p>        <pre>    T operator + (const T& a, const T& b); \n    T operator - (const T& a, const T& b); \n    T operator * (const T& a, const T& b); \n    T operator / (const T& a, const T& b);    </pre>        <p>Not only that, but since we want the type to be a field (as it's what people have intuition for), the overloads should        be defined as such that the following rules hold true:</p>        <ol>            <li>For every \\(a\\) and \\(b\\) of \\(T\\), \\(a \\circ b = b \\circ a\\), where \\(\\circ\\) is any of \\(+, *\\). In other words            addition and multiplication should be commutative.</li>            <li>There must be two <i>distinct</i> elements \\(e_1\\) and \\(e_2\\) of the type \\(T\\) such that, for any \\(a\\) of \\(T\\), \\(a+e_1 = a\\)            and \\(a*e_2 = a\\). You can see that those two elements are supposed to imitate the behaviour of zero in addition and one in multiplication, respectively.            We call these the <i>addition identity</i> and <i>multiplication identity</i> respectively.</li>            <li>Subtraction (\\(-\\)) and Division (\\(/\\)) should work in such a way that for every \\(a\\) of \\(T\\), \\(a - a = e_1\\) and \\(a/a = e_2\\).            So, like with numbers, subtracting something from itself should yield the addition identity and dividing something from itself should yield the            multiplication identity.</li>            <li>When comibining all those operations together, they should be distributive (so, for every \\(a\\),\\(b\\) and \\(c\\) of \\(T\\),            you should have: \\(a*(b+c) = a*b + a*c\\).</li>        </ol>        <p>Now, there could be cases where there's no sense in defining one \"group\" of operations; for example,        in pointer arithmetic, only addition (and subsequently, subtraction), makes sense, as it        literally represents moving from one memory position to another, but multiplication (and division) doesn't. Hence, it's also acceptable        if one only defines overloads for either \\(+\\) (and \\(-\\)) or \\(*\\) (and \\(/\\)), still        applying the above rules. This, in math, is known as an <i>abelian group.</i></p>        <p>If you have overloaded the addition and multiplication operators, then you should overload the        modulo operator only in the following scenario and following manner:</p>        <p><i>For every \\(a\\), \\(b\\) and \\(r\\) of \\(T\\), there must be a unique element \\(n\\)        of \\(T\\) such that \\(a = n*b + r\\) holds true. Only in that case then, \\(%\\) shall        be overloaded and satisfy: \\(a\\,\\%\\,b = r\\).</i></p>        <p>There's a last situation where I'd consider it acceptable to overload all these        operators. Assume you have two types \\(T\\) and \\(V\\). \\(T\\) is defined as a        field, as discussed above, but you also have the following overloads:</p>        <pre>    V operator + (const V& u, const V& v); \n    V operator - (const V& u, const V& v); \n    V operator * (const T& a, const V& u);     </pre>        <p>Someone may suspect what is going on. These, in fact, are the declarations for        <i>vector addition</i> (\\(+\\) and \\(-\\)) and <i>scalar multiplication</i> \\(*\\), fundamental operations        of what we call \"vector spaces\". Similarly to fields, some rules must apply to how        those operations work, if they are to truly represent those of a vector space, but        they are similar enough to those of a field.</p>        <ol>            <li>Vector addition (specifically \\(+\\)) needs to be commutative.</li>            <li>There must be an element \\(w\\) of \\(V\\) such that every vector subtracted            from itself will yield it (\\(u - u = w\\), for every \\(u\\) of \\(V\\)). This            \\(w\\) is similar to the zero vector (\\(\\vec{0}\\)) for the common vectors that            consist of tuples of numbers.</li>            <li>The additive identity of \\(T\\) when multiplied with any vector \\(u\\)            of \\(V\\) must yield the \\(w\\) mentioned in (2) (so, for every \\(u\\) of \\(V\\),            \\(e_1*u = w\\)).</li>            <li>Similarly to the previous case, vector addition and scalar multiplication must            be distributive. So for any \\(a\\) of \\(T\\) and any two \\(u\\) and \\(v\\) of \\(V\\), you            must have \\(a*(u + v) = a*u + a*v\\).</li>        </ol>        <p>Of course, as you may have noted, in the case where you want the basic arithmetic        operators to be used for vectors, division doesn't make much sense to be used. You also        shouldn't use the multiplication operator for the dot and cross products of vectors;        you should just use proper function identifiers for these (for example, you can do         <code>T dot(const V& u, const V& v);</code> and <code>V cross(const V& u, const V& v);</code>)</p>                <h2>The increment and decrement operators (<code>++</code> and <code>--</code>)</h2>        <p>Those should always be accompanied by an overloaded <code>+</code> and <code>-</code>.        On top of that, your type should also have a notion of \"the next element\" and \"the previous element\".        In other words, if for your type it makes sense to put its elements on a line and \"move to the next one\"        or \"move to the previous one\", then you should use <code>++</code> and <code>--</code>, respectively,        to express those concepts.</p>        <h2>The bitshift operators (<code><<</code> and <code>>></code>)</h2>        <p>This one is a bit of a doozy, because, even though I generally like the STL,        their use of the bitshift operators is one I disagree with. Specifically, they are        used for string streams to input and output data.</p>        <p>However, I think you should overload those operators only in a way \"loyal\" to their        original use: To shift a number's digits up or down a place. How the builtin operator        achieves this, for example, is by dividing (for <code>>></code>) and by multiplying (for <code><<</code>)        the number on the left of the operator by \\(2\\) raised to the power indicated by the number        on the right. For numbers written in base \\(2\\), this has the effect of shifting the digits        down or up. And since for this base, they represent bits, the operators are called \"bitshifting operators\".</p>                <h2>The bit arithmetic operators (<code>~</code>, <code>&</code>, <code>|</code> and <code>^</code>)</h2>        <p>Similar to the bitshift operators, you should also remain loyal to the original function of these operators.        A good scenario I can think of where you could overload these operators is when you want to create a bitflag-like        object, so you can have stricter typing and use enum classes instead of preprocessor macros to define flags.</p>                <h2>The logical operators (<code>!</code>, <code>&&</code> and <code>||</code>)</h2>        <p>As mentioned in the introduction, those should only return boolean values. I also do not        find any reason to strafe away from their original purpose.</p>        <p>So, long story short, you should        only really overload those types for a user-defined type only if you intend said type        to be able to represent a logical value. Such types are usually integral types (like        integers), but really, any type for which the idea of \"being equal to\" and \"being different from\" is well defined        will do; in this case, you can pick one value to represent \"the truth\" and the other(s) to represent        \"the falsehood\" (this is, in fact, very similar to how booleans work: under the hood, they are integers        where 0 represents \"falsehood\", whilst        any non-zero integer is clumped together under the label \"truth\". </p>                <h2>The relational operators (<code>==</code>, <code>!=</code>, <code><</code>, <code>></code>, <code><=</code>, <code>>=</code> and <code><=></code>)</h2>        <p>As with the logical operators, those operators should also be restricted to returning boolean values (except for <code><=></code>        which returns an integer).        And, as their name suggests, they should be restricted to expressing propositions concering the relations        between members of a type; in more mathematical terms, they should be used for the ordering of the elemenets of        a type. </p>        <p>But what is an ordering anyways? First of all, to talk about orderings, we refer to two        operators. Those are the equality (\\(=\\)) operator and another one representing some type of        inequality, typically the \"lesser than\" inequality (\\(<\\)). All the other operators are        either combinations of those two or negations of those two or their combinations, so, in a sense        they aren't fundamental and thus, unnecessary to predefine them.</p>        <p>Despite our intuition, there's really no meaning attached to either of these operators, at least        no strict meaning. At most, if two elements of a type are \"equal\", that means they are indistinct and,        thus, the same element. But the \\(<\\) operator only imposes a hierarchy for the elements of a type,        a hierarchy which you are free to define however you want, no less (Although, specific fields in math        do require specific rules to be followed when defining this hierarchy).</p>        <p>Of course, just because you can define this hierarchy however you want, doesn't mean that        any such definition will be useful. Out of all those that one can conjure in their mind,        there are two types of ordering that are particularly useful. The first is called <i></i> total,        and it is when for any two elements \\(a\\), \\(b\\) and \\(c\\) of type \\(T\\), the following are true:</p>        <ul>            <li>\\(a = a\\). This property is called reflexivity. It essentially states the obvious; Something must be the same with itself. (Fun fact from            type theory: the reflexive property of equality is the only way the so called \"equality of elements of type\" type is (usually) introduced. Proving            that two things are equal in type theory, thus, consists of toying around with functions and replacements in order to end up with this reflexive equality).</li>            <li>If \\(a < b\\) and \\(b < c\\), then \\(a < c\\). In other words, total ordering is transitive.</li>            <li>\\(a < b\\) and \\(b < a\\) being true at the same time is impossible.</li>            <li>If \\(a \\neq b\\) (\\(\\neq\\) being the negation of \\(=\\)), then either            \\(a < b\\) or \\(b < a\\) must be true (but obviously not both at the same time,            as imposed by the previous rule).</li>        </ul>        <p>On top of that, if you take any subset of the elements of \\(T\\), and you find that        it has an element that is lesser than any other element in that subset (except for itself, obviously),        then this is called a <i>well-ordering</i>.</p>        <p>The other type of ordering is called <i>partial</i> ordering and its difference is that        the last rule (about either \\(a = b\\), \\(a < b\\) or \\(b < a\\) being true) needs not apply.<p>        <p>I think you know where this is going. Overloading the relational operators (except for <code><=></code>) should        ensure that the type they are overloaded for is, at least, partially ordered.</p>        <p>Of course, I mentioned only <code>==</code> and <code><</code>, but it is clear what the other        operators should be:</p>        <ul>            <li>\\(a \\neq b\\) is \"not \\(a = b\\)\"</li>            <li>\\(a \\leq b\\) is \"\\(a = b\\) or \\(a < b\\)\".</li>            <li>\\(a > b\\) is \"not \\(a \\leq b\\)\".</li>            <li>\\(a \\geq b\\) is \"not \\(a < b\\)\".</li>        </ul>        <p>If        you want to overload <code><=></code> as well, then you need to ensure a total ordering,        as it essentially checks the last rule mentioned for a total order. (First <code>a <=> b</code> checks \\(a = b\\),        and returns 0 on success. If it fails, it checks whether \\(a < b\\), and it returns a positive integer on success,        otherwise it assumes \\(b < a\\) and it sends a negative integer.</p>        <p>Fun math fact: set theory tells        you that you can always find a well-ordering for any set you can think of. This often causes        confusion, as we learn, for example, that complex numbers \"cannot be ordered\". This is a bit of        a miscommunication though, as what this \"cannot be ordered\" refers to is that they cannot be an <i>ordered field</i>,        not an ordered set! If you remember from the part about overloading the arithmetic operators, a field        behaves like how we expect \"numbers\" to behave, informally speaking. And an \"ordered field\" not only has        a well-ordering, but it imposes extra rules on how this ordering must be, so as to keep this intuition intact. Thus,        if you plan for a type to both overload the arithmetic operators and the relational operators, ensure that        for any three elements \\(a\\), \\(b\\) and \\(c\\) of \\(T\\):</p>        <ul>            <li>If \\(a \\circ b\\) then \\((a + c) \\circ (b + c)\\), where \\(\\circ\\) stands            for any relational operator.</li>            <li>If \\(a = b\\) then \\(a*c = b*c\\).</li>            <li>If \\(a > 0\\) and \\(b > 0\\) then \\(a*b > 0\\), where \\(0\\) refers to the additive identity of the type.</li>            <li>Likewise, if \\(a < 0\\) and \\(b < 0\\), then \\(a*b > 0\\).</li>            <li>However, if \\(a < 0\\) but \\(b > 0\\), then \\(a*b < 0\\).</li>        </ul>        <p>Essentially, those rules define how \"positives\" and \"negatives\" behave. For any        \"positives\" you multiply together, the result is also positive. For any \"negatives\"        you multiply together, the result is positive. If you multiply a \"negative\" with a \"positive\"        the result must be a \"negative\".</p>                <h2>The subscript operator (<code>[]</code>)</h2>        <p>This is simple enough. The subscript operator should be overloaded for an object that        has an \"array\" or \"container\" like structure. In other words, somoene should overload the        operator like this:</p>        <pre>    template< typename I >\n    concept Integral = std::is_integral< I >\n    \n    template< typename U, Integral I >\n    class T {\n        // members of class\n    public:\n        U& operator [] (I i) const;\n    };        </pre>        <p></p>        <p>In other words, the subscript operator should NOT modify the object that overloads it        and instead should return a left reference to an object of type \\(U\\) which is contained        in an appropriate (non static) structure within objects of type \\(T\\). And because of that        semantic, this requires that <code>I</code> is an integral type, since it does not make intuitive        sense to access positions in a container or an array using something like a <code>float</code>.</p>                <h2>The pointer and address operators (<code>*</code> and <code>&</code>)</h2>        <p>The only way you should overload the pointer operator is if you intend to make        a type that \"looks like\" a pointer but is meant to be memory safe. For examples,        see smart pointers, iterators and other such constructs of the STL. It should also        allow for pointer arithmetics, if such a thing makes sense for your type at least, so        it should be accompanied by proper overloading of the <code>+</code>, <code>-</code>, <code>++</code>        and <code>--</code> operators.</p>        <p>As for the address operator, I am strongly against overloading it. It should always        be reserved for getting the address of an object, nothing more, nothing less.</p>                <h2>The function call operator (<code>()</code>)</h2>        <p>This operator has the least restrictions on how it should be overloaded out of all.        It is commonly used for        making function objects, sometimes also known as functors. Function objects are,        in a sense, generalisations of functions, with the ability to have an internal state.        This could be useful, for example, as a simple implementation of asynchronous functions        (although the C++20 standard now defines coroutines, albeit they are quite complicated).</p>        <p>As stated before, because of the nature of function objects, you are completely free        on what this operator will do when overloaded. In fact, you are also free to have side effects        with this overload.</p>        <p>Fun fact: Lambda expressions in C++ are, in fact, syntax sugar for function objects.        During compilation, the compiler turns the lambda expression into a class that overloads        the <code>()</code> operator.</p>                <h2>The member/pointer of member access of pointer operators (<code>-></code> and <code>->*</code>)</h2>        <p><code>-></code> is special, in the sense that it's quite restricted in what it can        do. Specifically, it can only be overloaded as a function with no arguments that returns        a pointer to an object or an object that has overloaded the operator. Once it reaches        a pointer, this recursive process stops and then member lookup is performed.</p>        <p><code>->*</code> on the other hand is not restricted at all, and can be a function of        any two arguments.</p>        <p>Due to this idiosyncracy, I strongly believe that you should avoid at any cost to overload        either of these operators. Only reasonable situation to overload the operator I can think of is when your        object contains another object whose members you'd like to make visible to the end user.</p>                <h2>The assignment operators (<code>=</code> and co.)</h2>        <p>As said in the general rules of thumb, first of all, these operators must always return a left        reference to the object they operate on (so, the functions should always end with <code>return *this;</code>).</p>        <p>Other than that, they should be accompanied by an overload of the relational operator <code>==</code>. Specifically, you should        ensure that if you have something like the following:</p>        <pre>    T obj1( /* initialization */ );\n    T obj2( /* initialization */ );\n    \n    if ( obj1 = obj2; \n         obj1 == obj2 ) { \n        return 0;\n    } else { \n        return 1;\n    }        </pre>        <p>Then you will always have '0' be returned. In other words, assigment must work in such a way        that the assigned object will be equal to the assignee after the assignment. Of course, it        <i>can</i> make sense that (after conversion), an element of some type is \"equal to\" or \"can be assigned\" an        element of another type; try to ensure the same thing as above in these cases as well.</p>        <p>For \"compound\" assigment operators, always make sure the overload respects the following:</p>        <ul>            <li><code>obj1 _= obj2</code> is the same as <code>obj1 = obj1 _ obj2</code>, where <code>_</code> stands            for any operator <code>=</code> is paired with.</li>        </ul>        <p>NOTE: You shouldn't confuse the assignment operator(s) with the constructors of an object (even though some objects            can use <code>=</code> as part of their initialization syntax). They are different things altogether (and you should prefer            the <code>{ /*expression*/ }</code> to the <code>= /* expression */</code> initialization syntax anyways; it has the added benefit that it protects            against narrowing).</p>                <h1>Conclusion</h1>        <p>And this is all I have to say about the matter. For some operators I had to say more stuff compared        to others and, truth be told, this list may seem extremely restrictive when it comes to overloading.</p>        <p>Of course, I think it goes without saying that all these are but mere suggestions, aimed        to minimize potential misunderstandings when reviewing (or writing) code. (Almost) Nothing stops you        from giving the wildest definitions imaginable to your overloads. Or you may work under a        specification at a workplace which orders different rules for overloading operators, in which case        you should probably stick to those rules. Whatever is the case, have fun overloading, but never cease        to be cautious!</p>        "
      }
    },
    {
      "slug": "vulkan_concepts_part1",
      "hotwords": ["code", "graphics", "vulkan"],
      "title": {
        "en": "Learning the basics of Vulkan: Part 1",
        "el": "Μαθαίνοντας τα βασικά της Vulkan: Μέρος 1 (Αγγλικά)"
      },
      "featured_image": "https://upload.wikimedia.org/wikipedia/commons/f/fe/Vulkan_logo.svg",
      "summary": {
        "en": "An introduction to the basic concepts of Vulkan",
        "el": "Μια εισαγωγή στα θεμελιώδη της Vulkan"
      },
      "updated": "2024-05-13T00:00:00.000Z",
      "published": "2024-03-04T00:00:00.000Z",
      "author": "Mantis",
      "body": {
        "en": "<p>Up until some years ago, two were the main, dominant graphics APIs;         OpenGL and DirectX. Both were great, and enabled people to build amazing things         in the domain of graphical applications. However, both came with their own set         of pitfalls.</p>                <p>DirectX, whilst extremely powerful, is only available on Windows. Not only         that, but DirectX's ability mostly stops at graphics. Whilst it does provide compute         capabilities, it does not delve deep into them, and they are mainly used as         a helping hand in graphical applications.<p>                <p>OpenGL, whilst not being as limited in reach as DirectX, has its own set         of issues. It abstracts way too much over the GPU and generally the graphics         pipeline, leaving the programmer unable to really finetune their application         and squeeze that last drop of performance. As for computing, it suffers         the same fate as DirectX. It negelects compute capabilities other than having         the bare necessities, which, similarly, exist only to serve the graphics pipelines.        </p>                <p>A new API was needed. One that could combine the best of both worlds.         The cross-platform capabilities of OpenGL, and the low-level, high-performance         of DirectX. Not only that, but it would be perfect if it was also easily         extensible, so that it could be used for more than just graphics, without needing         to jump ship to another API, such as CUDA or OpenCL.         And thus, the Khronos Group, the same group that created OpenGL,         gave birth to the Vulkan specification, in 2016.</p>            <figure>                <img src=\"https://upload.wikimedia.org/wikipedia/commons/f/fe/Vulkan_logo.svg\" alt=\"undefined\" width=\"327\" height=\"308\"></p>                <figcaption>Fig. 1: Vulkan logo.\n Vulkan and the Vulkan logo are registered trademarks of the Khronos Group Inc.</figcaption>            </figure>        <p>However, quickly, Vulkan gained a specific reputation. Whilst it provided         the utmost control over a GPU, and not only in graphics, but compute and transfer        operations as well, this came at the cost of the API's friendliness to the         programmer. Maybe the most notorious example of this is the Vulkan implementation         \"Hello World\" of         graphics applications: In Vulkan, to draw <i>the triangle</i>        you'd end up writing as many as <i>1 000</i> lines of code! Not only         this, but those lines of code aren't exactly straightforward either; The user         has to learn a lot of new concepts in order to be able to even begin drawing basic         geometry!</p>                <p>But I do believe that Vulkan's difficulty is greatly overstated. Whilst         the size of information that one needs to know is, admitedly, not small,         getting a bit acquainted with the main concepts is much easier than it seems.         </p>        <p>        In this post, I want to go over the general \"morphology\" of the Vulkan API. What to expect         from its syntax, its general conventions, this sort of thing. In another post, I will         go over the main concepts that concern the mechanics of the API (which are not just         specific to Vulkan, but apply to any grahpics API).        </p>        <p>        <i>Nitpicking note: Technically speaking, Vulkan is not an API, but a specification for an API.        In other words, it's a document that describes how someone's API should look and         behave in order to be considered a Vulkan API. However, for the sake of simplicity,         I will refer to it as an API.</i>        </p>        <h1>The general conventions of the Vulkan API</h1>        <p>A good API is first and foremost based on good syntax conventions. Vulkan is no different.         The nice thing about it, as well, is that the conventions are simple enough.         The casing convention is <code>camelCase</code>.        The naming of identifiers is the following: </p>        <ul>            <li><i>Functions</i> get prefixed with <code>vk</code>. There             are further conventions concerning them:             <ul>                <li><i>Host side functions</i> (i.e. functions that get excecuted                     the moment they are called from the code, by the host itself)                     have verbs that describe their general purpose right after the                     prefix. Some of the most common                     verbs one may stumble onto are:                     <ul>                        <li><code>Create</code> is used for functions which create                         handles to objects necessary for the API to function. (example: <code>vkCreateInstance</code>)</li>                        <li><code>Destroy</code>, predictably, is used for                         functions which destroy the handles created by the API. (example: <code>vkDestroyInstance</code>)</li>                        <li><code>Allocate</code> is similar to <code>Create</code>                         with the difference that it implies the API doesn't use new                         resources to create the handles. Rather, it depends on already                         created handles, and uses the resources they offer so they can                         be created. (example: <code>vkAllocateMemory</code>)</li>                        <li><code>Free</code> is the equivalent of <code>Destroy</code>                         for handles created with <code>Allocate</code>. (example: <code>vkFreeMemory</code>)</li>                        </li>                        <li><code>Get</code> is used for functions that query information                         from anything the API interfaces with. Most common usecase is when                         trying to query information about the GPU. (example: <code>vkGetPhysicalDeviceProperties</code>)</li>                        <li><code>Bind</code>. In Vulkan, you will often find yourself creating                         handles of objects that represent resources on the GPU but are not                         directly accessible by the GPU. This is why Vulkan offers functions that                         bind those handles to actual GPU resources (mainly memory). The convention                         is that after the verb, the two following nouns are the handle to be bound and                         the resource it will be bound to respectively. (example: <code>vkBindBufferMemory</code>, which                         binds buffers, the simplest form of data storage in Vulkan, to GPU memory)</li>                        <li><code>Reset</code>. Some handles are associated, in the specification,                         to a cycle of usage. A common example is command buffers, which begin in the                         <i>initial</i> state, which is an empty state, of sorts, they are then recorded (move                         to the <i>recorded</i> state), submitted (<i>pending</i> state), executed (<i>executed</i>                         state) etc. The API allows the user to bring some of the handles back to their                         initial state, so they can be overwritten and used again. (example: <code>vkResetCommandBuffer</code>)</li>                    </ul>                    Note that there aren't types of functions like <code>Reallocate</code>                     or <code>Set</code>. This is because of one of the core philosophies of Vulkan;                     immutability. Once you have created or allocated something,                     it cannot be changed (in terms of used resources). Do note though that a lot of Vulkan objects do                     support the usage of caches or previous objects to speed up their own                     creation.                 </li>                 <li> The other type of functions that Vulkan offers is <i>device commands</i>.                 Those, unlike host side functions, are not executed once called. Instead, what                 they do is record a command to a command buffer, which is to be submitted and                 executed by a device later in the program. Those functions <i>always</i> have the                 infix <code>Cmd</code> follow the prefix <code>vk</code>.                And since they are commands, the <code>Cmd</code> prefix is always followed by a verb                 (example: <code>vkCmdDraw</code>).                 </li>            </ul>            </li>            <li><p><i>Handles</i>, <i>Enums</i> and <i>Structs</i> get prefixed with <code>Vk</code>             (similar to functions but the first letter is uppercase.</p>            <p>A really useful thing to remember, for structs, is that those used to pass             information to functions, such as handle creation functions, are oftentimes             named similarly to those functions. They are prefixed with <code>Info</code>             and the verb of the function is placed <i>after</i> the handle name. This             is especially useful for finding the related documentation for those structs             as they can often contain a lot of fields and are hard to remember. (example:             the struct used for swapchain creation [the <code>vkCreateSwapchain</code> function]             is called <code>vkSwapchainCreateInfo</code>).</p></li>        </ul>        <p>Another important convention is the addition of a couple of capital letters on the end         of some identifiers. Those identify two things: First, that the identifier is part of an         extension, which implies both that the identifier cannot be used unless it is imported         during instance or device creation. Second, the letters tell who is the creator of the         extension and that a device supporting Vulkan may not necessarily support the extension         the identifier belongs to. So, for example, identifiers ending with <code>KHR</code> are made by the         Khronos Group itself, and identifiers ending with <code>NV</code> are made by Nvidia.</p>                <p>        In addition, for parameters and struct fields, Vulkan uses a \"weak\" form of Hungarian         notation. By this, I mean that it prefixes pointers with <code>p</code> and arrays         with <code>pp</code> (so, as double pointers). Since, for Vulkan, arrays are pointers,         always expect a field adjacent to any array that is meant to hold the number of elements <i>in</i>         the array. So, the struct <code>VkDeviceCreateInfo</code>, for example, contains <code>ppEnabledExtensionNames</code>         and also <code>enabledExtensionCount</code>, the names of the extensions you want to activate for         a device and how many of these extensions you have in your double pointer. Other than         pointers, though, as I showed with the previous example, Vulkan does not use the Hungarian         notation. Instead, it just describes the field.</p>        <p>Last but not least, every struct contains an         <code>sType</code> field, an enum which identifies it. The value of the field is         usually easy to remember, as it generally has the form <code>VK_STRUCTURE_TYPE_</code>         followed by the name of the struct. (example: <code>VK_STRUCTURE_TYPE_SWAPCHAIN_CREATE_INFO_KHR</code>)        </p>        <p>Final note: Some names of functions and structs have the number 2 appended on them. For structs         this usually means that they are actually linked lists where extensions can extend on the \"2-less\"         structs (example: <code>vkPhysicalDeviceExtensions2</code>). On the other hand, functions that have 2 appended on them tend to replace the usual Vulkan model         of passing function arguments through structs for multiple function arguments instead. An exception         to this is getter functions, where the 2 simply implies they return structs (or arrays of structs) whose type name         has 2 appended on them. Note that the 2 <i>always</i> precedes the extension acronym (example:         <code>vkGetPhysicalDeviceSurfaceCapabilities2KHR</code>).</p>        <h2>The \"modes\" of the Vulkan API</h2>        <p>One of the best things about Vulkan is how <i>consistent</i> it is as an API;         you always know the general flow and form of commands when it comes to using it.         Hence, you can divide the API into a rough set of \"modes\" each of which has a         rather predictable structure and a rather predictable outcome.</p>        <h3>Querying information</h3>        <p>Obviously, to make an API all about using the GPU usable itself, we need         to be able to learn as much as we can about it.</p>        <p>The way Vulkan presents this information is through the use of structs and arrays.         To get these from Vulkan, you always use functions that start with <code>vkGet</code>.        Those functions are always void in their type, so the way they return information is through         the use of pointers. Hence, the usual process to query and retrieve such info is the following: </p>                <ol>                    <li> Create a struct representing the \"returned\" data structure, or a dynamic                     array type (an <code>std::vector</code> object in C++, or a combo of an unsigned integer                     and pointer to the struct type the array is going to hold, in C, for example) that holds such structs,                     if the function returns arrays </li>                    <li>If the function returns arrays, then you first must querry the size of the array (Thus, the argument                     that returns the actual data must be set to <code>NULL</code> first time you call the function).                     Since getter functions                     are void in Vulkan, checking if the size returned is nonzero is imperative for proper error checking.</li>                     <li>Call the function a second time, this time using both the -returned- size of the array, if applicable,                     and the variable that holds the (array of) struct(s) itself. Should everything go correctly, you now have                     done a proper query and the data is immediately usable. This part of the process should not, generally, fail                     (unless you are unlucky enough to get an Out of Memory error).</li>                </ol>        <p>An example of such process can be seen here:</p>         <pre>    VkPhysicalDeviceProperties properties; \n    vkGetPhysicalDeviceProperties(physicalDevice, &properties);         </pre>        <p>And if you have an array:</p>         <pre>    uint32_t extensionCount; \n    vkEnumerateDeviceExtensionProperties(physicalDevice, nullptr, &extensionCount, nullptr); \n    std::vector&ltVkExtensionProperties&gt availableExtensions(extensionCount); \n    vkEnumerateDeviceExtensionProperties(physicalDevice, nullptr, &extensionCount, availableExtensions.data());         </pre>        <p></p>        <figcaption><i>NOTE: In both of these examples, <code>physicalDevice</code> is a variable         of type <code>VkPhysicalDevice</code> and is assumed it's created sometime before the imaginary         program that would contain the presented snippets of code.</i></figcaption>        <p></p>        <h3>Creating handles</h3>        <p>Of course, having data about the GPU is not enough. We also want to do stuff with it.         For the majority of the time, Vulkan allows the programmer to interact with the GPU through the         use of handles. Those are immutable objects that represent resources on the GPU.         The process of creating them is rather straightforward:</p>        <ol>            <li> Create the struct responsible for passing info for the handle's creation.             Remember, those structs always take the form <code>vk</code> <i>+ [handle name] +</i> <code>CreateInfo</code>.             Alternatively, you can pass the creation parameters directly to the creation function, by             using its variant with a 2 appended on it. However, do note that this might make your code more unreadable.             </li>            <li> Create a variable that will hold the handle, its type being the appropriate handle             you want to create. Obviously, it will be initialized as <code>NULL</code> first.             It's especially important to remember that Vulkan handles are, under the hood, struct pointers, so you always             need to be cautious when using them. Vulkan does not check for null handles when you pass them             to functions, which means that dereferencing a null handle <i>will</i> cause a segmentation fault. </li>            <li> Call the function that creates the handle. The function is always prefixed with <code>vkCreate</code>.             The function's arguments are the struct with the creation info, the handle variable and, usually             a handle which acts as a parent to the created handle. The newly created handle's address will be placed             in the variable you passed to the function. Note that creation functions return an error code (Their type is <code>VkResult</code>).             Also, upon failure, the handle variable will remain null. Thus, it's always prudent to check             the error code, especially because a lot of times it's descriptive enough to tell you specifically what went             wrong. For example, if you use a window creation API like GLFW, which tend to implicitly             initalize OpenGL, if you try to create a Vulkan swapchain for a window created by the afore mentioned             API, <i>without</i> requesting that the created window is API-less,             Vulkan will throw an error code complaining the window already has a graphics API             associated with it. </li>        </ol>        <p> For handles that are allocated, instead of created, the process is identical         with the only exception being that creation functions are now allocation functions (hence         their names use <code>Allocate</code> instead of <code>Create</code>. Same goes for the info structs).        </p>        <p>Since I mentioned that some handles act as parents to other handles, here are some common relationships         between handles (I will discuss on a later post what these handles are specifically):</p>        <ul>            <li><code>VkInstance</code> >> <code>VkSurface</code></li>            <li><code>VkInstance</code> >> <code>VkDevice</code> >> <code>VkSwapchain</code></li>            <li><code>VkInstance</code> >> <code>VkDevice</code> >> <code>VkRenderPass</code></li>            <li><code>VkInstance</code> >> <code>VkDevice</code> >> <code>VkPipeline</code></li>            <li><code>VkInstance</code> >> <code>VkDevice</code> >> <code>VkCommandPool</code> >> <code>VkCommandBuffer</code></li>            <li><code>VkInstance</code> >> <code>VkDevice</code> >> <code>VkMemory</code></li>            <li><code>VkInstance</code> >> <code>VkDevice</code> >> <code>VkBuffer</code> OR <code>VkImage</code></li>        </ul>        <p>Note that this is not an exhaustive list, nor does it show interconnections between handles.         For example, a <code>VkSwapchain</code> will require a <code>VkSurface</code> to be created,         which is passed through its creation info struct. It only shows what handle you are expected to         pass as a parent handle when creating (or allocating) another handle. An interesting observation is that the <code>VkDevice</code>         is probably the most important handle in Vulkan, as it's the parent of a huge number of other Vulkan handles.         Of course, this is expected for a GPU API. </p>        <p>Here is an example of the creation of an instance handle (instances being the \"root\" of all         Vulkan applications, will be discussed in another part):</p>        <pre>    VkInstance instance{ nullptr }; \n    VkApplicationInfo appInfo{ \n        .sType{ VK_STRUCTURE_TYPE_APPLICATION_INFO }, \n        .pApplicationName{ \"Hello Triangle\" }, \n        .applicationVersion{ VK_MAKE_VERSION(1, 0, 0) }, \n        .pEngineName{ \"No Engine\" }, \n        .engineVersion{ VK_MAKE_VERSION(1, 0, 0) }, \n        .apiVersion{ VK_API_VERSION_1_3 } \n    }; \n    VkInstanceCreateInfo createInfo{ \n        .sType{ VK_STRUCTURE_TYPE_INSTANCE_CREATE_INFO }, \n        .pApplicationInfo{ &appInfo } \n    }; \n    VkResult err{ VK_SUCCESS }; \n    if( ( err = vkCreateInstance(&createInfo, nullptr, &instance) )\n            != VK_SUCCESS ) { \n        std::cerr << \"An error happened here!\\n\"; \n    }        </pre>        <figcaption><i>NOTE: As you may have noticed in the example, creation functions         have one additional argument. This is a pointer to a custom allocator,         in case you want memory allocation to not use the default one. It's usually        not necessary in most cases, unless you are working with an application where         super-efficient memory management is extremely crucial, so it's usually set to         <code>nullptr</code>. Another thing to note is that some functions may contain even more         arguments than the parent handle, the created handle and the allocator. For example         pipeline creation functions also contain cache information arguments, which         greatly help decrease the time needed to create a pipeline.</i></figcaption>    <h3>Recording commands</h3>    <p>As revealed earlier, commands (that the GPU will execute) are not executed     the moment they are called. Instead, they are recorded to a command buffer, which     then is submitted to a queue (a command buffer is simply a chunk of memory containing     instructions for the GPU, and a queue is hardware on the GPU that is responsible for     executing those instructions. More on a later post). The process of recording command buffers     contains the following steps:     </p>    <ol>        <li>First, you have to create the resources for the command buffers. This is simply done         by creating a command pool with a device and then allocating a command buffer from that         pool.</li>        <li>Then, you begin recording the command buffer. This is done by calling the following function:         <code>vkBeginCommandBuffer</code>. The function takes the command buffer and a struct.         This struct isn't really important, unless you want to use secondary command buffers (        which are practically subcommands to be executed by main commands).</li>        <li>After you have begun recording, you are ready to record the commands.         As mentioned above, a command is any function that starts with <code>vkCmd</code>.         Note that the order of the commands are important, as their execution is sequential. </li>        <li>After you have recorded all the commands, you must end the recording, by using the function         <code>vkEndCommandBuffer</code>. This function takes the command buffer as its only argument. </li>    </ol>    <p>A simple example of the above process is the following: </p>    <pre>    VkCommandPool commandPool{ nullptr }; \n    VkCommandBuffer commandBuffer{ nullptr }; \n    VkCommandPoolCreateInfo poolInfo{ \n        .sType{ VK_STRUCTURE_TYPE_COMMAND_POOL_CREATE_INFO }, \n        .queueFamilyIndex{ queueFamilyIndex } \n    }; \n    vkCreateCommandPool(device, &poolInfo, nullptr, &commandPool); \n\n    VkCommandBufferAllocateInfo allocInfo{ \n        .sType{ VK_STRUCTURE_TYPE_COMMAND_BUFFER_ALLOCATE_INFO }, \n        .commandPool{ commandPool }, \n        .level{ VK_COMMAND_BUFFER_LEVEL_PRIMARY }, \n        .commandBufferCount{ 1 } \n    }; \n    vkAllocateCommandBuffers(device, &allocInfo, &commandBuffer); \n\n    VkCommandBufferBeginInfo beginInfo{ \n        .sType{ VK_STRUCTURE_TYPE_COMMAND_BUFFER_BEGIN_INFO } \n    }; \n    vkBeginCommandBuffer(commandBuffer, &beginInfo); \n\n    vkCmdBindPipeline(commandBuffer, VK_PIPELINE_BIND_POINT_GRAPHICS, graphicsPipeline); \n    vkCmdDraw(commandBuffer, 3, 1, 0, 0); \n\n    vkEndCommandBuffer(commandBuffer);    </pre>    <figcaption><i>NOTE: The above command isn't really a proper way to do something like drawing     on the screen or executing a pipeline. The actual process is more involved and requires     knowing some additional concepts, such as the concept of a render pass, which I will     discuss in a later post. This is just a simple example to show the general process of     recording commands. </i></figcaption>    <p></p>    <h3>Miscellaneous actions</h3>    <p>There are other actions that one can do with Vulkan that don't fit in the above     categories. Usually, those represent actions that the host can do and are usually     the most direct way to interact with the GPU (like when it's time to submit commands).    Some other times, they are used to     interface with the windowing system when you want to ask for resources related     to graphics (like the display, if you want exclusive fullscreen).     There's not a specific pattern to them, so I will not go into detail about them here.     </p>    <h1>Conclusion</h1>    <p>Of course, this is not an exhaustive guide on how the Vulkan API works. There are many nooks and crannies     that make it up and a blog post is simply not enough to make sense of it all.     However, simply knowing the above is enough to get you far into Vulkan, at least     far enough to be able to make sense of the official documentation and some of the     available tutorials that exist out there. The rest is just a matter of being curious     and learning graphics programming, both of which are independent of this specific     API and apply to any old graphics related programming interface.</p>    <p>On the note of official documentation, I want to note that it is probably     one of the best documentations I have ever seen. It is extremely detailed and     covers almost every aspect of the API. The most exceptional thing about it is that     it's simply just the specification of the API, broken down into chunks; this     is not only an interesting fact, considering that specifications are usually     the last place the average programmer would look for for guidance, especially     a novice one, but it's also a testament, at least in my eyes, to the quality     of the API as a whole. </p>    "
      }
    },
    {
      "slug": "example_post",
      "hotwords": ["example", "random"],
      "title": {
        "en": "Example Post",
        "el": "Παράδειγμα"
      },
      "featured_image": "./src/assets/hehe.jpg",
      "summary": {
        "en": "This is an example post",
        "el": "Μια ανάρτηση-παράδειγμα"
      },
      "updated": "2024-01-20T00:00:00.000Z",
      "published": "2024-01-20T00:00:00.000Z",
      "author": "Mantis",
      "body": {
        "en": "<h1>This is an example post</h1>\n                <p>I hope everything works properly.</p>\n                <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit,                sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.                 Quam lacus suspendisse faucibus interdum posuere lorem ipsum.                 Tincidunt id aliquet risus feugiat in ante metus dictum at.                 Ultricies lacus sed turpis tincidunt id aliquet risus feugiat in.                 In massa tempor nec feugiat nisl. Lectus urna duis convallis convallis                 tellus id interdum velit laoreet. Purus non enim praesent elementum                 facilisis leo vel fringilla. Senectus et netus et malesuada fames ac                 turpis egestas. Iaculis urna id volutpat lacus laoreet non.                 Elit ullamcorper dignissim cras tincidunt lobortis feugiat vivamus at.                 Quam nulla porttitor massa id. Risus sed vulputate odio ut enim.                 Imperdiet sed euismod nisi porta. Malesuada pellentesque elit eget                 gravida cum. Morbi leo urna molestie at elementum.                 Consectetur libero id faucibus nisl tincidunt eget nullam non nisi.</p>\n                <p>I will put an image here, to see how it looks:</p>\n                <p><img src=\"https://cyber-mantid.xyz/src/assets/hehe.jpg\" alt=\"undefined\" width=\"327\" height=\"308\"></p>\n                <p>Mesmerizing, no?</p>\n                <p>I will also test a youtube video here:</p>\n                <p><iframe width=\"597\" height=\"336\" src=\"https://www.youtube.com/embed/rXbfwabZLds\" title=\"Fully Operational, Huh?\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen=\"allowfullscreen\"></iframe></p>\n                <p>Adipiscing tristique risus nec feugiat in fermentum. Nibh mauris cursus mattis                 molestie a. Ipsum dolor sit amet consectetur adipiscing elit duis.                 Consectetur adipiscing elit pellentesque habitant morbi. Sapien eget mi                 proin sed libero. Tellus pellentesque eu tincidunt tortor aliquam.                 Nulla porttitor massa id neque aliquam vestibulum morbi. Auctor urna                 nunc id cursus metus aliquam eleifend. Arcu cursus vitae congue mauris rhoncus                 aenean vel. Tempus urna et pharetra pharetra massa massa ultricies mi quis.                 Turpis cursus in hac habitasse platea dictumst. Nec ullamcorper sit amet risus.                 Nisl purus in mollis nunc sed. Integer eget aliquet nibh praesent tristique magna                 sit amet. Auctor eu augue ut lectus. Lorem donec massa sapien faucibus et                 molestie ac feugiat. Diam quam nulla porttitor massa id. Pulvinar sapien et                 ligula ullamcorper malesuada proin libero nunc consequat. Nunc non blandit                 massa enim nec dui nunc mattis enim. Amet volutpat consequat mauris nunc congue.</p>\n                <p>Does latex work? Let's see:</p>\n                <p>$$f(x) = \\int_0^xt^2dt$$</p>\n                <p>Vulputate ut pharetra sit amet aliquam id. Non consectetur a erat                 nam at lectus urna. Vitae turpis massa sed elementum tempus egestas sed sed risus.                 Et netus et malesuada fames. Orci ac auctor augue mauris augue neque gravida in.                 Sed faucibus turpis in eu mi bibendum neque egestas congue. Ipsum dolor sit amet                 consectetur adipiscing. Praesent tristique magna sit amet purus gravida quis blandit.                 Nisl purus in mollis nunc sed id semper risus in.                 Justo laoreet sit amet cursus sit amet dictum sit. Consectetur adipiscing                 elit ut aliquam purus sit. Dolor morbi non arcu risus quis. Adipiscing commodo                 elit at imperdiet dui accumsan sit. Nisi porta lorem mollis aliquam ut porttitor leo.                 Viverra aliquet eget sit amet tellus cras adipiscing. Nibh tortor id                 aliquet lectus proin nibh nisl.</p>\n<p>Nunc faucibus a pellentesque sit amet.                 Duis ut diam quam nulla. Donec ac odio tempor orci dapibus ultrices in iaculis nunc.                 Feugiat nibh sed pulvinar proin gravida. Sodales ut etiam sit amet nisl purus. Et molestie                ac feugiat sed. Malesuada proin libero nunc consequat interdum varius sit amet mattis.                 Amet consectetur adipiscing elit duis tristique sollicitudin. Ipsum dolor sit amet                 consectetur adipiscing elit duis. Etiam tempor orci eu lobortis elementum nibh.                 Ultrices vitae auctor eu augue. Risus ultricies tristique nulla aliquet enim.                 Blandit cursus risus at ultrices mi. Sed pulvinar proin gravida hendrerit.                 Eleifend quam adipiscing vitae proin sagittis nisl.</p>\n                <p>Scelerisque fermentum dui faucibus in. Enim facilisis gravida neque convallis                 a cras. Ipsum dolor sit amet consectetur adipiscing elit pellentesque habitant.                 Urna porttitor rhoncus dolor purus non. Ridiculus mus mauris vitae ultricies leo                 integer malesuada. Ultrices vitae auctor eu augue ut lectus arcu bibendum at.                 Sit amet cursus sit amet. Eleifend mi in nulla posuere sollicitudin aliquam                 ultrices sagittis. Tincidunt praesent semper feugiat nibh sed pulvinar proin                 gravida hendrerit. Et netus et malesuada fames ac turpis egestas integer eget.                 Turpis egestas maecenas pharetra convallis posuere morbi. Netus et malesuada fames                 ac turpis egestas sed tempus urna. Elit sed vulputate mi sit amet mauris commodo                 quis. Facilisis sed odio morbi quis commodo odio aenean.</p>\n<p></p>"
      }
    }
  ]
}
